# –°–±–æ—Ä–Ω–∏–∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á DevOps
## –î–ª—è –æ—Ç—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ Proxmox/Linux (Fedora/Ubuntu)

---

## üü¢ JUNIOR DEVOPS ENGINEER

### –ó–∞–¥–∞—á–∞ 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL
**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ë–î —Å —Ä–æ—Ç–∞—Ü–∏–µ–π

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –°–æ–∑–¥–∞—Ç—å –¥–∞–º–ø PostgreSQL –±–∞–∑—ã
- –ò—Å–∫–ª—é—á–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É `logs` –∏–∑ –±—ç–∫–∞–ø–∞
- –î–æ–±–∞–≤–∏—Ç—å timestamp –∫ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
- –°–∂–∞—Ç—å –≤ .tar.gz
- –•—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –±—ç–∫–∞–ø–æ–≤
- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —á–µ—Ä–µ–∑ cron –Ω–∞ –∑–∞–ø—É—Å–∫ –≤ 2:00

**–†–µ—à–µ–Ω–∏–µ:**

```bash
#!/bin/bash
# backup_postgres.sh

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
DB_NAME="myapp"
DB_USER="postgres"
BACKUP_DIR="/var/backups/postgresql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="backup_${DB_NAME}_${TIMESTAMP}.sql"
RETENTION_DAYS=7

# –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
mkdir -p $BACKUP_DIR

# –°–æ–∑–¥–∞—ë–º –¥–∞–º–ø –∏—Å–∫–ª—é—á–∞—è —Ç–∞–±–ª–∏—Ü—É logs
pg_dump -U $DB_USER \
  --exclude-table=logs \
  --format=plain \
  $DB_NAME > $BACKUP_DIR/$BACKUP_FILE

# –°–∂–∏–º–∞–µ–º
tar -czf $BACKUP_DIR/$BACKUP_FILE.tar.gz -C $BACKUP_DIR $BACKUP_FILE
rm $BACKUP_DIR/$BACKUP_FILE

# –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
find $BACKUP_DIR -name "backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
if [ $? -eq 0 ]; then
    echo "[$(date)] Backup successful: $BACKUP_FILE.tar.gz" >> /var/log/db_backup.log
else
    echo "[$(date)] Backup FAILED" >> /var/log/db_backup.log
    exit 1
fi
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PostgreSQL –Ω–∞ Ubuntu/Fedora:**
```bash
# Ubuntu
sudo apt update && sudo apt install postgresql postgresql-contrib -y

# Fedora
sudo dnf install postgresql postgresql-server -y
sudo postgresql-setup --initdb
sudo systemctl enable --now postgresql

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –±–∞–∑—ã
sudo -u postgres psql -c "CREATE DATABASE myapp;"
sudo -u postgres psql -d myapp -c "CREATE TABLE logs (id serial, message text);"
sudo -u postgres psql -d myapp -c "CREATE TABLE users (id serial, name text);"
```

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ cron:**
```bash
# –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∞–≤–∞ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
chmod +x /path/to/backup_postgres.sh

# –î–æ–±–∞–≤–∏—Ç—å –≤ crontab
crontab -e
# –î–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–∫—É:
0 2 * * * /path/to/backup_postgres.sh
```

---

### –ó–∞–¥–∞—á–∞ 2: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ CPU –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞
**–¶–µ–ª—å:** –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU –ø—Ä–æ—Ü–µ—Å—Å–æ–º –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–∞

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –ü—Ä–æ–≤–µ—Ä—è—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
- –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç >80% CPU –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –º–∏–Ω—É—Ç
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å
- –û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ –ª–æ–≥

**–†–µ—à–µ–Ω–∏–µ:**

```bash
#!/bin/bash
# monitor_cpu.sh

SERVICE_NAME="nginx"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à —Å–µ—Ä–≤–∏—Å
CPU_THRESHOLD=80
CHECK_COUNT=5
COUNTER_FILE="/tmp/cpu_high_counter_${SERVICE_NAME}"
LOG_FILE="/var/log/cpu_monitor.log"

# –ü–æ–ª—É—á–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∞
CPU_USAGE=$(ps aux | grep -v grep | grep $SERVICE_NAME | awk '{sum+=$3} END {print int(sum)}')

# –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –Ω–µ –Ω–∞–π–¥–µ–Ω
if [ -z "$CPU_USAGE" ]; then
    echo "[$(date)] Service $SERVICE_NAME not running" >> $LOG_FILE
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞
if [ $CPU_USAGE -gt $CPU_THRESHOLD ]; then
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫
    if [ -f $COUNTER_FILE ]; then
        COUNT=$(cat $COUNTER_FILE)
        COUNT=$((COUNT + 1))
    else
        COUNT=1
    fi
    echo $COUNT > $COUNTER_FILE
    
    echo "[$(date)] High CPU: ${CPU_USAGE}% (count: ${COUNT}/${CHECK_COUNT})" >> $LOG_FILE
    
    # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ 5 —Ä–∞–∑ –ø–æ–¥—Ä—è–¥ - –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º
    if [ $COUNT -ge $CHECK_COUNT ]; then
        echo "[$(date)] RESTARTING $SERVICE_NAME due to high CPU" >> $LOG_FILE
        systemctl restart $SERVICE_NAME
        rm -f $COUNTER_FILE
    fi
else
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –µ—Å–ª–∏ CPU –≤ –Ω–æ—Ä–º–µ
    rm -f $COUNTER_FILE
fi
```

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞:**
```bash
chmod +x /path/to/monitor_cpu.sh

# –î–æ–±–∞–≤–∏—Ç—å –≤ crontab –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
* * * * * /path/to/monitor_cpu.sh
```

---

### –ó–∞–¥–∞—á–∞ 3: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Nginx reverse proxy —Å SSL
**–¶–µ–ª—å:** –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Nginx –∫–∞–∫ –æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å HTTPS

**–†–µ—à–µ–Ω–∏–µ:**

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Nginx
# Ubuntu
sudo apt install nginx certbot python3-certbot-nginx -y

# Fedora
sudo dnf install nginx certbot python3-certbot-nginx -y

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Nginx
sudo cat > /etc/nginx/sites-available/myapp << 'EOF'
upstream backend {
    server 127.0.0.1:3000;
}

server {
    listen 80;
    server_name myapp.local;

    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Websocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
    
    # Health check
    location /nginx-health {
        access_log off;
        return 200 "healthy\n";
    }
}
EOF

# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥
sudo ln -s /etc/nginx/sites-available/myapp /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx

# –î–ª—è —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω–æ–≥–æ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞ (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
    -keyout /etc/ssl/private/nginx-selfsigned.key \
    -out /etc/ssl/certs/nginx-selfsigned.crt \
    -subj "/C=US/ST=State/L=City/O=Org/CN=myapp.local"
```

---

### –ó–∞–¥–∞—á–∞ 4: Docker Compose –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Å–µ—Ä–≤–∏—Å–∞–º–∏

**–†–µ—à–µ–Ω–∏–µ:**

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=development
      - DATABASE_URL=postgresql://postgres:password@db:5432/myapp
      - REDIS_URL=redis://redis:6379
    volumes:
      - ./src:/app/src
      - ./node_modules:/app/node_modules
    depends_on:
      - db
      - redis
    command: npm run dev

  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=myapp
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

  adminer:
    image: adminer
    ports:
      - "8080:8080"
    depends_on:
      - db

volumes:
  postgres_data:
  redis_data:
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
docker-compose up -d

# –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤
docker-compose logs -f app

# –û—Å—Ç–∞–Ω–æ–≤–∫–∞
docker-compose down

# –ü–µ—Ä–µ—Å–±–æ—Ä–∫–∞ –ø–æ—Å–ª–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π
docker-compose up -d --build
```

---

### –ó–∞–¥–∞—á–∞ 5: –ë–∞–∑–æ–≤—ã–π CI/CD —Å Git hooks
**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–µ–ø–ª–æ–π –ø—Ä–∏ push –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π

**–†–µ—à–µ–Ω–∏–µ:**

```bash
# –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ —Å–æ–∑–¥–∞—ë–º bare —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
sudo mkdir -p /opt/git/myapp.git
cd /opt/git/myapp.git
sudo git init --bare

# –°–æ–∑–¥–∞—ë–º post-receive hook
cat > /opt/git/myapp.git/hooks/post-receive << 'EOF'
#!/bin/bash

DEPLOY_DIR="/var/www/myapp"
BACKUP_DIR="/var/www/myapp_backup"
LOG_FILE="/var/log/deploy.log"

echo "[$(date)] Starting deployment..." >> $LOG_FILE

# –°–æ–∑–¥–∞—ë–º backup —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
if [ -d $DEPLOY_DIR ]; then
    rm -rf $BACKUP_DIR
    cp -r $DEPLOY_DIR $BACKUP_DIR
fi

# –ö–ª–æ–Ω–∏—Ä—É–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
rm -rf $DEPLOY_DIR
git clone /opt/git/myapp.git $DEPLOY_DIR

cd $DEPLOY_DIR

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
npm install >> $LOG_FILE 2>&1

# –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
pm2 restart myapp || pm2 start app.js --name myapp

echo "[$(date)] Deployment completed" >> $LOG_FILE
EOF

chmod +x /opt/git/myapp.git/hooks/post-receive

# –ù–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ
git remote add production ssh://user@server:/opt/git/myapp.git
git push production main
```

---

## üü° MIDDLE DEVOPS ENGINEER

### –ó–∞–¥–∞—á–∞ 6: Kubernetes –∫–ª–∞—Å—Ç–µ—Ä –Ω–∞ Proxmox VM (K3s)
**–¶–µ–ª—å:** –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π Kubernetes –∫–ª–∞—Å—Ç–µ—Ä

**–†–µ—à–µ–Ω–∏–µ:**

```bash
#!/bin/bash
# install_k3s_cluster.sh

# –ù–∞ –º–∞—Å—Ç–µ—Ä-–Ω–æ–¥–µ
curl -sfL https://get.k3s.io | sh -s - server \
  --write-kubeconfig-mode 644 \
  --disable traefik

# –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –¥–ª—è worker –Ω–æ–¥
sudo cat /var/lib/rancher/k3s/server/node-token

# –ù–∞ worker –Ω–æ–¥–∞—Ö
K3S_URL=https://master-ip:6443
K3S_TOKEN=your-node-token

curl -sfL https://get.k3s.io | K3S_URL=$K3S_URL K3S_TOKEN=$K3S_TOKEN sh -

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ (–Ω–∞ –º–∞—Å—Ç–µ—Ä–µ)
kubectl get nodes
kubectl get pods -A
```

**–î–µ–ø–ª–æ–π —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:**
```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-demo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 80
```

---

### –ó–∞–¥–∞—á–∞ 7: –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (Prometheus + Grafana)
**–¶–µ–ª—å:** –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç–µ–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥–ª—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

**–†–µ—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Docker Compose:**

```yaml
# docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3000:3000"
    restart: unless-stopped
    depends_on:
      - prometheus

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:
```

**prometheus.yml:**
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

rule_files:
  - "alerts.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
```

---

### –ó–∞–¥–∞—á–∞ 8: Ansible –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫—É –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–µ—Ä–≤–µ—Ä–æ–≤

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:**
```
ansible/
‚îú‚îÄ‚îÄ ansible.cfg
‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îî‚îÄ‚îÄ hosts.yml
‚îú‚îÄ‚îÄ roles/
‚îÇ   ‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îú‚îÄ‚îÄ webserver/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îî‚îÄ‚îÄ playbooks/
    ‚îî‚îÄ‚îÄ site.yml
```

**inventory/hosts.yml:**
```yaml
all:
  children:
    webservers:
      hosts:
        web1:
          ansible_host: 192.168.1.10
        web2:
          ansible_host: 192.168.1.11
    
    databases:
      hosts:
        db1:
          ansible_host: 192.168.1.20
```

**playbooks/site.yml:**
```yaml
---
- name: Configure all servers
  hosts: all
  become: yes
  roles:
    - common

- name: Configure web servers
  hosts: webservers
  become: yes
  roles:
    - webserver

- name: Configure database servers
  hosts: databases
  become: yes
  roles:
    - database
```

---

### –ó–∞–¥–∞—á–∞ 9: Terraform –¥–ª—è Proxmox
**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ VM —á–µ—Ä–µ–∑ Infrastructure as Code

**main.tf:**
```hcl
terraform {
  required_providers {
    proxmox = {
      source  = "telmate/proxmox"
      version = "2.9.14"
    }
  }
}

provider "proxmox" {
  pm_api_url      = var.proxmox_api_url
  pm_api_token_id = var.proxmox_api_token_id
  pm_api_token_secret = var.proxmox_api_token_secret
  pm_tls_insecure = true
}

resource "proxmox_vm_qemu" "devops_vm" {
  count       = var.vm_count
  name        = "${var.vm_name}-${count.index + 1}"
  target_node = var.proxmox_node
  clone       = var.template_name
  
  cores   = var.cpu_cores
  sockets = 1
  memory  = var.memory
  
  disk {
    size    = var.disk_size
    type    = "scsi"
    storage = var.storage
  }
  
  network {
    model  = "virtio"
    bridge = "vmbr0"
  }
  
  ipconfig0 = "ip=${var.ip_address_base}.${count.index + 10}/24,gw=${var.gateway}"
  sshkeys = file(var.ssh_public_key_file)
}
```

---

### –ó–∞–¥–∞—á–∞ 10: –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å ELK Stack
**–¶–µ–ª—å:** –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–±–æ—Ä –∏ –∞–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤

**docker-compose.yml:**
```yaml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    user: root
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    depends_on:
      - elasticsearch
      - logstash

volumes:
  elasticsearch_data:
```

---

## üî¥ SENIOR DEVOPS ENGINEER

### –ó–∞–¥–∞—á–∞ 11: GitOps —Å ArgoCD
**–¶–µ–ª—å:** –í–Ω–µ–¥—Ä–∏—Ç—å GitOps –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Kubernetes

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ ArgoCD:**
```bash
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

# Port-forward –¥–ª—è –¥–æ—Å—Ç—É–ø–∞
kubectl port-forward svc/argocd-server -n argocd 8080:443
```

**ArgoCD Application –º–∞–Ω–∏—Ñ–µ—Å—Ç:**
```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-prod
  namespace: argocd
spec:
  project: default
  
  source:
    repoURL: https://github.com/yourorg/gitops-repo.git
    targetRevision: main
    path: apps/production/myapp
  
  destination:
    server: https://kubernetes.default.svc
    namespace: production
  
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false
    syncOptions:
    - CreateNamespace=true
    
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m
```

---

### –ó–∞–¥–∞—á–∞ 12: High Availability PostgreSQL —Å Patroni
**–¶–µ–ª—å:** –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤—ã–π –∫–ª–∞—Å—Ç–µ—Ä –ë–î

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ –∫–∞–∂–¥—É—é –Ω–æ–¥—É:**
```bash
#!/bin/bash
# install_patroni.sh

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
sudo apt update
sudo apt install -y postgresql postgresql-contrib etcd python3-pip python3-psycopg2

# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Patroni
sudo pip3 install patroni[etcd]

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Patroni
sudo cat > /etc/patroni.yml << EOF
scope: postgres-cluster
namespace: /db/
name: $(hostname)

restapi:
  listen: 0.0.0.0:8008
  connect_address: $(hostname -I | awk '{print $1}'):8008

etcd:
  hosts: 192.168.1.10:2379,192.168.1.11:2379,192.168.1.12:2379

bootstrap:
  dcs:
    ttl: 30
    loop_wait: 10
    retry_timeout: 10
    maximum_lag_on_failover: 1048576
    postgresql:
      use_pg_rewind: true
      parameters:
        max_connections: 100
        shared_buffers: 256MB

  initdb:
    - encoding: UTF8
    - data-checksums

  pg_hba:
    - host replication replicator 0.0.0.0/0 md5
    - host all all 0.0.0.0/0 md5

postgresql:
  listen: 0.0.0.0:5432
  connect_address: $(hostname -I | awk '{print $1}'):5432
  data_dir: /var/lib/postgresql/14/main
  bin_dir: /usr/lib/postgresql/14/bin
  authentication:
    replication:
      username: replicator
      password: rep-pass
    superuser:
      username: postgres
      password: postgres-pass
EOF

# Systemd service
sudo cat > /etc/systemd/system/patroni.service << EOF
[Unit]
Description=Patroni (PostgreSQL HA)
After=syslog.target network.target

[Service]
Type=simple
User=postgres
Group=postgres
ExecStart=/usr/local/bin/patroni /etc/patroni.yml
KillMode=process
TimeoutSec=30
Restart=no

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable patroni
sudo systemctl start patroni
```

---

### –ó–∞–¥–∞—á–∞ 13: Disaster Recovery —Å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π
**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å —Å–∏—Å—Ç–µ–º—É —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Å–µ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

**disaster_recovery_backup.sh:**
```bash
#!/bin/bash
# disaster_recovery_backup.sh

set -euo pipefail

BACKUP_ROOT="/mnt/backup"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="$BACKUP_ROOT/$TIMESTAMP"
LOG_FILE="/var/log/dr_backup.log"
RETENTION_DAYS=30

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
mkdir -p $BACKUP_DIR/{databases,configs,containers,vms,apps}

log "=== Starting Disaster Recovery Backup ==="

# 1. Backup –≤—Å–µ—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
backup_databases() {
    # PostgreSQL
    if systemctl is-active --quiet postgresql; then
        pg_dumpall -U postgres | gzip > $BACKUP_DIR/databases/postgresql_all.sql.gz
        log "PostgreSQL backup completed"
    fi
    
    # MySQL/MariaDB
    if systemctl is-active --quiet mysql; then
        mysqldump --all-databases --single-transaction | gzip > $BACKUP_DIR/databases/mysql_all.sql.gz
        log "MySQL backup completed"
    fi
}

# 2. Backup –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
backup_configs() {
    tar -czf $BACKUP_DIR/configs/etc.tar.gz \
        /etc/nginx \
        /etc/systemd/system \
        /etc/ssh \
        2>/dev/null || true
    
    log "Configuration backup completed"
}

# 3. Backup Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏ volumes
backup_docker() {
    if command -v docker &> /dev/null; then
        docker ps -a --format "{{.Names}}" > $BACKUP_DIR/containers/container_list.txt
        
        # Backup volumes
        docker volume ls -q | while read volume; do
            docker run --rm -v $volume:/data -v $BACKUP_DIR/containers:/backup \
                alpine tar czf /backup/volume_$volume.tar.gz -C /data .
        done
        
        log "Docker backup completed"
    fi
}

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤
backup_databases
backup_configs
backup_docker

# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –∞—Ä—Ö–∏–≤–∞
cd $BACKUP_ROOT
tar -czf backup_$TIMESTAMP.tar.gz $TIMESTAMP

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
find $BACKUP_ROOT -name "backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete

# –†–∞—Å—á–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã
sha256sum backup_$TIMESTAMP.tar.gz > backup_$TIMESTAMP.tar.gz.sha256

log "=== Backup completed successfully ==="
log "Backup location: $BACKUP_ROOT/backup_$TIMESTAMP.tar.gz"
```

---

### –ó–∞–¥–∞—á–∞ 14: Security Hardening –∏ Compliance
**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º

**security_audit.sh:**
```bash
#!/bin/bash
# security_audit.sh

set -euo pipefail

REPORT_DIR="/var/log/security_audit"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
REPORT_FILE="$REPORT_DIR/audit_$TIMESTAMP.txt"

mkdir -p $REPORT_DIR

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $REPORT_FILE
}

log "=== Security Audit Report ==="
log "Hostname: $(hostname)"
log "OS: $(lsb_release -d | cut -f2)"

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Å–∏—Å—Ç–µ–º—ã
log "\n--- System Updates ---"
if apt list --upgradable 2>/dev/null | grep -q upgradable; then
    UPDATES=$(apt list --upgradable 2>/dev/null | grep upgradable | wc -l)
    log "‚ö†Ô∏è  $UPDATES security updates available"
else
    log "‚úÖ System is up to date"
fi

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ—Ä—Ç–æ–≤
log "\n--- Open Ports ---"
ss -tuln | grep LISTEN >> $REPORT_FILE

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ SSH –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
log "\n--- SSH Configuration ---"
if grep -q "^PermitRootLogin yes" /etc/ssh/sshd_config 2>/dev/null; then
    log "‚ùå Root login is enabled"
else
    log "‚úÖ Root login is disabled"
fi

if grep -q "^PasswordAuthentication yes" /etc/ssh/sshd_config 2>/dev/null; then
    log "‚ö†Ô∏è  Password authentication is enabled"
else
    log "‚úÖ Password authentication is disabled"
fi

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ firewall
log "\n--- Firewall ---"
if systemctl is-active --quiet ufw; then
    log "‚úÖ Firewall is active"
    ufw status >> $REPORT_FILE
else
    log "‚ùå No firewall is active"
fi

# 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ fail2ban
log "\n--- Fail2ban ---"
if systemctl is-active --quiet fail2ban; then
    log "‚úÖ Fail2ban is active"
else
    log "‚ö†Ô∏è  Fail2ban is not running"
fi

# 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –Ω–∞ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Ñ–∞–π–ª—ã
log "\n--- File Permissions ---"
for file in /etc/passwd /etc/shadow; do
    PERMS=$(stat -c %a $file)
    log "$file: $PERMS"
done

# 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ SUID/SGID —Ñ–∞–π–ª–æ–≤
log "\n--- SUID/SGID Files ---"
find / -type f \( -perm -4000 -o -perm -2000 \) 2>/dev/null | head -20 >> $REPORT_FILE

# 8. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –≤—Ö–æ–¥–∞
log "\n--- Failed Login Attempts ---"
grep "Failed password" /var/log/auth.log 2>/dev/null | tail -10 >> $REPORT_FILE || log "No recent failed attempts"

# 9. –ü—Ä–æ–≤–µ—Ä–∫–∞ Docker –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
if command -v docker &> /dev/null; then
    log "\n--- Docker Security ---"
    PRIV_CONTAINERS=$(docker ps --format "{{.Names}}" | xargs -I {} docker inspect {} --format '{{.Name}}: Privileged={{.HostConfig.Privileged}}' | grep "Privileged=true" || echo "None")
    log "Privileged containers: $PRIV_CONTAINERS"
fi

# 10. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
log "\n--- Disk Space ---"
df -h | awk '$5+0 > 80 {print "‚ö†Ô∏è  "$0}' >> $REPORT_FILE

log "\n=== Audit Completed ==="
log "Full report: $REPORT_FILE"
```

---

### –ó–∞–¥–∞—á–∞ 15: Blue-Green Deployment
**–¶–µ–ª—å:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–µ–ø–ª–æ—è –±–µ–∑ –ø—Ä–æ—Å—Ç–æ—è —Å–µ—Ä–≤–∏—Å–∞

**blue_green_deploy.sh:**
```bash
#!/bin/bash
# blue_green_deploy.sh

set -euo pipefail

APP_NAME="myapp"
BLUE_PORT=3000
GREEN_PORT=3001
HEALTH_CHECK_URL="http://localhost"
NGINX_UPSTREAM="/etc/nginx/conf.d/${APP_NAME}_upstream.conf"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–µ–∫—É—â—É—é –∞–∫—Ç–∏–≤–Ω—É—é —Å—Ä–µ–¥—É
get_active_env() {
    if grep -q "server 127.0.0.1:$BLUE_PORT" $NGINX_UPSTREAM && \
       ! grep -q "^[[:space:]]*#.*server 127.0.0.1:$BLUE_PORT" $NGINX_UPSTREAM; then
        echo "blue"
    else
        echo "green"
    fi
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
health_check() {
    local port=$1
    local max_attempts=30
    local attempt=0
    
    log "Checking health on port $port..."
    
    while [ $attempt -lt $max_attempts ]; do
        if curl -sf "${HEALTH_CHECK_URL}:${port}/health" > /dev/null; then
            log "Health check passed on port $port"
            return 0
        fi
        
        attempt=$((attempt + 1))
        log "Health check attempt $attempt/$max_attempts failed, retrying..."
        sleep 2
    done
    
    log "ERROR: Health check failed on port $port"
    return 1
}

# –î–µ–ø–ª–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
deploy_app() {
    local env=$1
    local port=$2
    
    log "Deploying to $env environment (port $port)..."
    
    # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é
    pm2 delete ${APP_NAME}-${env} 2>/dev/null || true
    
    # –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–¥
    cd /opt/${APP_NAME}
    git pull origin main
    npm install --production
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
    PORT=$port pm2 start app.js --name ${APP_NAME}-${env}
    
    sleep 5
    health_check $port
}

# –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞—Ñ–∏–∫
switch_traffic() {
    local target_env=$1
    local target_port=$2
    
    log "Switching traffic to $target_env environment..."
    
    cat > $NGINX_UPSTREAM << EOF
upstream ${APP_NAME}_backend {
    server 127.0.0.1:${target_port} max_fails=3 fail_timeout=30s;
}
EOF
    
    nginx -t && nginx -s reload
    log "Traffic switched to $target_env"
}

# –û—Ç–∫–∞—Ç
rollback() {
    local previous_env=$1
    local previous_port=$2
    
    log "Rolling back to $previous_env..."
    
    if health_check $previous_port; then
        switch_traffic $previous_env $previous_port
        log "Rollback completed"
    else
        log "ERROR: Cannot rollback, previous version unhealthy"
        exit 1
    fi
}

# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
main() {
    local active_env=$(get_active_env)
    local target_env target_port previous_port
    
    if [ "$active_env" = "blue" ]; then
        target_env="green"
        target_port=$GREEN_PORT
        previous_port=$BLUE_PORT
    else
        target_env="blue"
        target_port=$BLUE_PORT
        previous_port=$GREEN_PORT
    fi
    
    log "=== Blue-Green Deployment Started ==="
    log "Current active: $active_env"
    log "Deploying to: $target_env"
    
    # –î–µ–ø–ª–æ–π –≤ –Ω–µ–∞–∫—Ç–∏–≤–Ω—É—é —Å—Ä–µ–¥—É
    if ! deploy_app $target_env $target_port; then
        log "Deployment failed"
        exit 1
    fi
    
    # –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞—Ñ–∏–∫
    switch_traffic $target_env $target_port
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è
    sleep 10
    if ! health_check $target_port; then
        log "New version unhealthy, rolling back..."
        rollback $active_env $previous_port
        exit 1
    fi
    
    # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é
    pm2 delete ${APP_NAME}-${active_env} 2>/dev/null || true
    
    log "=== Deployment Completed Successfully ==="
}

main "$@"
```

---

### –ó–∞–¥–∞—á–∞ 16: Canary Deployment –≤ Kubernetes
**–¶–µ–ª—å:** –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ç—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é

**canary-deployment.yml:**
```yaml
# –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-stable
spec:
  replicas: 9
  selector:
    matchLabels:
      app: myapp
      version: stable
  template:
    metadata:
      labels:
        app: myapp
        version: stable
    spec:
      containers:
      - name: myapp
        image: myapp:v1.0
        ports:
        - containerPort: 8080
---
# Canary –≤–µ—Ä—Å–∏—è (10% —Ç—Ä–∞—Ñ–∏–∫–∞)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-canary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myapp
      version: canary
  template:
    metadata:
      labels:
        app: myapp
        version: canary
    spec:
      containers:
      - name: myapp
        image: myapp:v2.0
        ports:
        - containerPort: 8080
---
# –û–±—â–∏–π Service
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  selector:
    app: myapp
  ports:
  - port: 80
    targetPort: 8080
```

**canary_promote.sh:**
```bash
#!/bin/bash
# canary_promote.sh - –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ canary —Ç—Ä–∞—Ñ–∏–∫–∞

APP="myapp"
NAMESPACE="default"

# –≠—Ç–∞–ø—ã canary: 10% -> 25% -> 50% -> 100%
STAGES=(1 3 5 9)
STABLE_STAGES=(9 7 5 1)

for i in "${!STAGES[@]}"; do
    CANARY_REPLICAS=${STAGES[$i]}
    STABLE_REPLICAS=${STABLE_STAGES[$i]}
    
    echo "Stage $((i+1)): Canary $CANARY_REPLICAS replicas, Stable $STABLE_REPLICAS replicas"
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å canary
    kubectl scale deployment ${APP}-canary -n $NAMESPACE --replicas=$CANARY_REPLICAS
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å stable
    kubectl scale deployment ${APP}-stable -n $NAMESPACE --replicas=$STABLE_REPLICAS
    
    # –ñ–¥–∞—Ç—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
    kubectl rollout status deployment/${APP}-canary -n $NAMESPACE
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏
    echo "Checking metrics for 5 minutes..."
    sleep 300
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å error rate (–ø—Ä–∏–º–µ—Ä —Å Prometheus)
    ERROR_RATE=$(curl -s "http://prometheus:9090/api/v1/query?query=rate(http_requests_total{job='myapp',status=~'5..'}[5m])" | jq -r '.data.result[0].value[1]')
    
    if (( $(echo "$ERROR_RATE > 0.01" | bc -l) )); then
        echo "Error rate too high ($ERROR_RATE), rolling back..."
        kubectl scale deployment ${APP}-canary -n $NAMESPACE --replicas=0
        kubectl scale deployment ${APP}-stable -n $NAMESPACE --replicas=10
        exit 1
    fi
done

# –ü–æ–ª–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
echo "Canary successful, promoting to stable..."
kubectl set image deployment/${APP}-stable myapp=myapp:v2.0
kubectl scale deployment ${APP}-canary -n $NAMESPACE --replicas=0
```

---

### –ó–∞–¥–∞—á–∞ 17: Service Mesh —Å Istio
**–¶–µ–ª—å:** –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞–º–∏ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º–∏

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Istio:**
```bash
# –°–∫–∞—á–∞—Ç—å Istio
curl -L https://istio.io/downloadIstio | sh -
cd istio-*
export PATH=$PWD/bin:$PATH

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å
istioctl install --set profile=demo -y

# –í–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π sidecar injection
kubectl label namespace default istio-injection=enabled
```

**–í–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å —Å traffic splitting:**
```yaml
# virtualservice.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - match:
    - headers:
        user-type:
          exact: beta
    route:
    - destination:
        host: myapp
        subset: v2
  - route:
    - destination:
        host: myapp
        subset: v1
      weight: 90
    - destination:
        host: myapp
        subset: v2
      weight: 10
---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp
spec:
  host: myapp
  subsets:
  - name: v1
    labels:
      version: v1
  - name: v2
    labels:
      version: v2
```

**Circuit Breaker –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
```yaml
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp-circuit-breaker
spec:
  host: myapp
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 50
        http2MaxRequests: 100
        maxRequestsPerConnection: 2
    outlierDetection:
      consecutiveErrors: 5
      interval: 30s
      baseEjectionTime: 30s
      maxEjectionPercent: 50
      minHealthPercent: 40
```

---

### –ó–∞–¥–∞—á–∞ 18: Secrets Management —Å Vault
**–¶–µ–ª—å:** –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ–∫—Ä–µ—Ç–∞–º–∏

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Vault:**
```bash
# Docker compose –¥–ª—è Vault
cat > vault-compose.yml << 'EOF'
version: '3.8'

services:
  vault:
    image: vault:latest
    container_name: vault
    ports:
      - "8200:8200"
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: myroot
      VAULT_DEV_LISTEN_ADDRESS: 0.0.0.0:8200
    cap_add:
      - IPC_LOCK
    volumes:
      - vault_data:/vault/data
      - vault_logs:/vault/logs

volumes:
  vault_data:
  vault_logs:
EOF

docker-compose -f vault-compose.yml up -d
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Kubernetes:**
```bash
# –í–∫–ª—é—á–∏—Ç—å Kubernetes auth
export VAULT_ADDR='http://localhost:8200'
export VAULT_TOKEN='myroot'

vault auth enable kubernetes

vault write auth/kubernetes/config \
    kubernetes_host="https://kubernetes.default.svc:443"

# –°–æ–∑–¥–∞—Ç—å –ø–æ–ª–∏—Ç–∏–∫—É
vault policy write myapp - <<EOF
path "secret/data/myapp/*" {
  capabilities = ["read"]
}
EOF

# –°–≤—è–∑–∞—Ç—å —Å service account
vault write auth/kubernetes/role/myapp \
    bound_service_account_names=myapp \
    bound_service_account_namespaces=default \
    policies=myapp \
    ttl=24h
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ Pod:**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: myapp
spec:
  serviceAccountName: myapp
  containers:
  - name: myapp
    image: myapp:latest
    env:
    - name: VAULT_ADDR
      value: "http://vault:8200"
  initContainers:
  - name: vault-agent
    image: vault:latest
    volumeMounts:
    - name: shared-data
      mountPath: /vault/secrets
    command:
    - sh
    - -c
    - |
      vault kv get -format=json secret/myapp/config > /vault/secrets/config.json
  volumes:
  - name: shared-data
    emptyDir: {}
```

---

### –ó–∞–¥–∞—á–∞ 19: Multi-Cloud Infrastructure
**–¶–µ–ª—å:** –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –æ–±–ª–∞–∫–∞—Ö

**Terraform multi-provider:**
```hcl
# providers.tf
terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }
    google = {
      source  = "hashicorp/google"
      version = "~> 5.0"
    }
    proxmox = {
      source  = "telmate/proxmox"
      version = "~> 2.9"
    }
  }
}

provider "aws" {
  region = var.aws_region
}

provider "azurerm" {
  features {}
}

provider "google" {
  project = var.gcp_project
  region  = var.gcp_region
}

provider "proxmox" {
  pm_api_url = var.proxmox_api_url
}
```

**–ú–æ–¥—É–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è VM –≤ —Ä–∞–∑–Ω—ã—Ö –æ–±–ª–∞–∫–∞—Ö:**
```hcl
# modules/compute/main.tf
variable "provider" {
  type = string
}

variable "instance_config" {
  type = object({
    name         = string
    instance_type = string
    disk_size    = number
  })
}

# AWS EC2
resource "aws_instance" "vm" {
  count         = var.provider == "aws" ? 1 : 0
  ami           = data.aws_ami.ubuntu.id
  instance_type = var.instance_config.instance_type
  
  tags = {
    Name = var.instance_config.name
  }
}

# Azure VM
resource "azurerm_linux_virtual_machine" "vm" {
  count               = var.provider == "azure" ? 1 : 0
  name                = var.instance_config.name
  resource_group_name = azurerm_resource_group.rg[0].name
  location            = azurerm_resource_group.rg[0].location
  size                = var.instance_config.instance_type
  
  os_disk {
    caching              = "ReadWrite"
    storage_account_type = "Standard_LRS"
  }
}

# Proxmox VM
resource "proxmox_vm_qemu" "vm" {
  count       = var.provider == "proxmox" ? 1 : 0
  name        = var.instance_config.name
  target_node = var.proxmox_node
  
  cores  = 2
  memory = 2048
}

output "ip_address" {
  value = (
    var.provider == "aws" ? aws_instance.vm[0].public_ip :
    var.provider == "azure" ? azurerm_linux_virtual_machine.vm[0].public_ip_address :
    var.provider == "proxmox" ? proxmox_vm_qemu.vm[0].default_ipv4_address :
    null
  )
}
```

---

### –ó–∞–¥–∞—á–∞ 20: Chaos Engineering
**–¶–µ–ª—å:** –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ —Å–∏—Å—Ç–µ–º—ã

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ Chaos Mesh:**
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å Chaos Mesh –≤ Kubernetes
curl -sSL https://mirrors.chaos-mesh.org/latest/install.sh | bash

# –ò–ª–∏ —á–µ—Ä–µ–∑ Helm
helm repo add chaos-mesh https://charts.chaos-mesh.org
helm install chaos-mesh chaos-mesh/chaos-mesh -n chaos-testing --create-namespace
```

**–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ö–∞–æ—Å–æ–º:**
```yaml
# pod-kill-experiment.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: pod-kill-experiment
  namespace: chaos-testing
spec:
  action: pod-kill
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: myapp
  scheduler:
    cron: '@every 10m'
---
# network-delay-experiment.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: NetworkChaos
metadata:
  name: network-delay
  namespace: chaos-testing
spec:
  action: delay
  mode: all
  selector:
    namespaces:
      - default
    labelSelectors:
      app: myapp
  delay:
    latency: "100ms"
    correlation: "100"
    jitter: "50ms"
  duration: "5m"
---
# cpu-stress-experiment.yaml
apiVersion: chaos-mesh.org/v1alpha1
kind: StressChaos
metadata:
  name: cpu-stress
  namespace: chaos-testing
spec:
  mode: one
  selector:
    namespaces:
      - default
    labelSelectors:
      app: myapp
  stressors:
    cpu:
      workers: 2
      load: 80
  duration: "3m"
```

**–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π chaos test runner:**
```bash
#!/bin/bash
# chaos_test_runner.sh

set -euo pipefail

CHAOS_NAMESPACE="chaos-testing"
APP_NAMESPACE="default"
METRICS_URL="http://prometheus:9090"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–µ—Ä–µ–¥ —Ç–µ—Å—Ç–æ–º
check_baseline() {
    log "Collecting baseline metrics..."
    
    BASELINE_ERROR_RATE=$(curl -s "$METRICS_URL/api/v1/query?query=rate(http_requests_total{status=~'5..'}[5m])" | jq -r '.data.result[0].value[1] // 0')
    BASELINE_LATENCY=$(curl -s "$METRICS_URL/api/v1/query?query=histogram_quantile(0.95,rate(http_request_duration_seconds_bucket[5m]))" | jq -r '.data.result[0].value[1] // 0')
    
    log "Baseline error rate: $BASELINE_ERROR_RATE"
    log "Baseline p95 latency: $BASELINE_LATENCY"
}

# –ó–∞–ø—É—Å—Ç–∏—Ç—å chaos —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç
run_chaos() {
    local experiment=$1
    
    log "Starting chaos experiment: $experiment"
    kubectl apply -f experiments/$experiment.yaml
    
    # –î–æ–∂–¥–∞—Ç—å—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
    sleep 360
    
    log "Chaos experiment completed"
}

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞
check_impact() {
    log "Collecting post-chaos metrics..."
    
    ERROR_RATE=$(curl -s "$METRICS_URL/api/v1/query?query=rate(http_requests_total{status=~'5..'}[5m])" | jq -r '.data.result[0].value[1] // 0')
    LATENCY=$(curl -s "$METRICS_URL/api/v1/query?query=histogram_quantile(0.95,rate(http_request_duration_seconds_bucket[5m]))" | jq -r '.data.result[0].value[1] // 0')
    
    log "Post-chaos error rate: $ERROR_RATE"
    log "Post-chaos p95 latency: $LATENCY"
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å SLO
    ERROR_THRESHOLD=0.01
    LATENCY_THRESHOLD=1.0
    
    if (( $(echo "$ERROR_RATE > $ERROR_THRESHOLD" | bc -l) )); then
        log "‚ùå ERROR: Error rate exceeded threshold"
        return 1
    fi
    
    if (( $(echo "$LATENCY > $LATENCY_THRESHOLD" | bc -l) )); then
        log "‚ùå ERROR: Latency exceeded threshold"
        return 1
    fi
    
    log "‚úÖ System passed chaos test"
    return 0
}

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
EXPERIMENTS=("pod-kill" "network-delay" "cpu-stress")

for exp in "${EXPERIMENTS[@]}"; do
    log "=== Testing: $exp ==="
    
    check_baseline
    run_chaos $exp
    
    if ! check_impact; then
        log "System failed chaos test: $exp"
        kubectl delete -f experiments/$exp.yaml
        exit 1
    fi
    
    kubectl delete -f experiments/$exp.yaml
    
    # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
    log "Cooling down for 5 minutes..."
    sleep 300
done

log "=== All chaos tests passed ==="
```

---

## üìö –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ï –ü–†–ê–ö–¢–ò–ö–ò

### –ó–∞–¥–∞—á–∞ 21: Observability Stack (–ü–æ–ª–Ω—ã–π —Å—Ç–µ–∫)
**–¶–µ–ª—å:** –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Ç—Ä–µ–π—Å–∏–Ω–≥

**docker-compose.yml –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å—Ç–µ–∫–∞:**
```yaml
version: '3.8'

services:
  # –ú–µ—Ç—Ä–∏–∫–∏
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"

  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    ports:
      - "3000:3000"

  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"

  # –¢—Ä–µ–π—Å–∏–Ω–≥
  jaeger:
    image: jaegertracing/all-in-one:latest
    environment:
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    ports:
      - "5775:5775/udp"
      - "6831:6831/udp"
      - "6832:6832/udp"
      - "5778:5778"
      - "16686:16686"
      - "14268:14268"
      - "14250:14250"
      - "9411:9411"

  # –ê–ª–µ—Ä—Ç—ã
  alertmanager:
    image: prom/alertmanager:latest
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"

volumes:
  prometheus_data:
  grafana_data:
  elasticsearch_data:
```

---

### –ó–∞–¥–∞—á–∞ 22: GitLab CI/CD Pipeline
**–¶–µ–ª—å:** –ü–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π CI/CD —Å —Ç–µ—Å—Ç–∞–º–∏, —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –¥–µ–ø–ª–æ–µ–º

**.gitlab-ci.yml:**
```yaml
stages:
  - build
  - test
  - security
  - deploy

variables:
  DOCKER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHORT_SHA
  KUBECONFIG: /root/.kube/config

# –°–±–æ—Ä–∫–∞
build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker build -t $DOCKER_IMAGE .
    - docker push $DOCKER_IMAGE
  only:
    - main
    - develop

# –Æ–Ω–∏—Ç-—Ç–µ—Å—Ç—ã
unit-tests:
  stage: test
  image: node:18
  script:
    - npm install
    - npm run test:unit
  coverage: '/Statements\s*:\s*(\d+\.\d+)%/'
  artifacts:
    reports:
      junit: junit.xml
      coverage_report:
        coverage_format: cobertura
        path: coverage/cobertura-coverage.xml

# –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã
integration-tests:
  stage: test
  image: docker:latest
  services:
    - docker:dind
    - postgres:14
  variables:
    DATABASE_URL: postgresql://postgres:password@postgres:5432/test
  script:
    - docker-compose -f docker-compose.test.yml up -d
    - npm run test:integration
    - docker-compose -f docker-compose.test.yml down

# Security —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
security-scan:
  stage: security
  image: aquasec/trivy:latest
  script:
    - trivy image --exit-code 1 --severity HIGH,CRITICAL $DOCKER_IMAGE
  allow_failure: true

# SAST —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
sast:
  stage: security
  image: returntocorp/semgrep:latest
  script:
    - semgrep --config=auto --json --output=sast-report.json
  artifacts:
    reports:
      sast: sast-report.json

# –î–µ–ø–ª–æ–π –≤ staging
deploy-staging:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config set-cluster k8s --server="$KUBE_URL" --insecure-skip-tls-verify=true
    - kubectl config set-credentials admin --token="$KUBE_TOKEN"
    - kubectl config set-context default --cluster=k8s --user=admin
    - kubectl config use-context default
    - kubectl set image deployment/myapp myapp=$DOCKER_IMAGE -n staging
    - kubectl rollout status deployment/myapp -n staging --timeout=5m
  environment:
    name: staging
    url: https://staging.example.com
  only:
    - develop

# –î–µ–ø–ª–æ–π –≤ production
deploy-production:
  stage: deploy
  image: bitnami/kubectl:latest
  script:
    - kubectl config set-cluster k8s --server="$KUBE_URL" --insecure-skip-tls-verify=true
    - kubectl config set-credentials admin --token="$KUBE_TOKEN"
    - kubectl config set-context default --cluster=k8s --user=admin
    - kubectl config use-context default
    - kubectl set image deployment/myapp myapp=$DOCKER_IMAGE -n production
    - kubectl rollout status deployment/myapp -n production --timeout=5m
  environment:
    name: production
    url: https://example.com
  when: manual
  only:
    - main
```

---

### –ó–∞–¥–∞—á–∞ 23: Cost Optimization
**–¶–µ–ª—å:** –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É

**cost_optimizer.sh:**
```bash
#!/bin/bash
# cost_optimizer.sh

set -euo pipefail

REPORT_FILE="/var/log/cost_report_$(date +%Y%m%d).txt"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $REPORT_FILE
}

log "=== Infrastructure Cost Analysis ==="

# 1. Kubernetes unused resources
log "\n--- Kubernetes Resource Analysis ---"

# –ù–∞–π—Ç–∏ pods —Å –Ω–∏–∑–∫–∏–º CPU usage
kubectl top pods -A | awk '$3 ~ /[0-9]+m$/ {if ($3+0 < 50) print $0}' | tee -a $REPORT_FILE

# –ù–∞–π—Ç–∏ unused PVCs
log "\nUnused Persistent Volume Claims:"
kubectl get pvc -A -o json | jq -r '.items[] | select(.status.phase=="Bound") | select(.spec.volumeName as $v | [kubectl get pods -A -o json | .items[] | select(.spec.volumes[]?.persistentVolumeClaim.claimName==$v)] | length == 0) | "\(.metadata.namespace)/\(.metadata.name)"' | tee -a $REPORT_FILE

# 2. Docker –æ–±—Ä–∞–∑—ã
log "\n--- Docker Images Analysis ---"
docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | sort -k3 -h -r | head -20 | tee -a $REPORT_FILE

# –ù–∞–π—Ç–∏ dangling images
DANGLING=$(docker images -f "dangling=true" -q | wc -l)
log "Dangling images: $DANGLING"

# 3. –°—Ç–∞—Ä—ã–µ backups
log "\n--- Old Backups ---"
find /var/backups -type f -mtime +30 -exec ls -lh {} \; | awk '{sum+=$5}END{print "Total size of old backups: "sum/1024/1024" MB"}' | tee -a $REPORT_FILE

# 4. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
log "\n--- Cost Optimization Recommendations ---"
log "1. Scale down underutilized pods"
log "2. Remove unused PVCs"
log "3. Cleanup old Docker images: docker image prune -a"
log "4. Review backup retention policies"
log "5. Consider spot/preemptible instances for non-critical workloads"

log "\n=== Report saved to $REPORT_FILE ==="
```

---

## üéØ –ò–¢–û–ì–û–í–´–ô –ü–†–û–ï–ö–¢

### –ó–∞–¥–∞—á–∞ 24: –ü–æ–ª–Ω–∞—è DevOps –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞
**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –ø–ª–∞—Ç—Ñ–æ—Ä–º—É —Å –≤—Å–µ–º–∏ best practices

**–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:**
1. Git (GitLab/Gitea)
2. CI/CD (GitLab CI / Jenkins)
3. Container Registry
4. Kubernetes Cluster
5. Monitoring (Prometheus + Grafana)
6. Logging (ELK Stack)
7. Secrets Management (Vault)
8. Service Mesh (Istio)
9. GitOps (ArgoCD)
10. Backup & DR

**deploy_platform.sh:**
```bash
#!/bin/bash
# deploy_platform.sh - –†–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ –ø–æ–ª–Ω–æ–π DevOps –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã

set -euo pipefail

PLATFORM_NAMESPACE="devops-platform"
DOMAIN="devops.local"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ Kubernetes
setup_kubernetes() {
    log "Setting up Kubernetes namespaces..."
    
    kubectl create namespace $PLATFORM_NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -
    kubectl create namespace logging --dry-run=client -o yaml | kubectl apply -f -
    kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -
}

# 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Istio
install_istio() {
    log "Installing Istio..."
    istioctl install --set profile=demo -y
    kubectl label namespace default istio-injection=enabled
}

# 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
install_monitoring() {
    log "Installing Prometheus and Grafana..."
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring
}

# 4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
install_logging() {
    log "Installing ELK Stack..."
    helm repo add elastic https://helm.elastic.co
    helm install elasticsearch elastic/elasticsearch -n logging
    helm install kibana elastic/kibana -n logging
    helm install filebeat elastic/filebeat -n logging
}

# 5. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ ArgoCD
install_argocd() {
    log "Installing ArgoCD..."
    kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
}

# 6. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Vault
install_vault() {
    log "Installing Vault..."
    helm repo add hashicorp https://helm.releases.hashicorp.com
    helm install vault hashicorp/vault -n $PLATFORM_NAMESPACE
}

# 7. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ GitLab
install_gitlab() {
    log "Installing GitLab..."
    helm repo add gitlab https://charts.gitlab.io/
    helm install gitlab gitlab/gitlab \
        --set global.hosts.domain=$DOMAIN \
        --set certmanager-issuer.email=admin@$DOMAIN \
        -n $PLATFORM_NAMESPACE
}

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
main() {
    log "=== Starting DevOps Platform Deployment ==="
    
    setup_kubernetes
    install_istio
    install_monitoring
    install_logging
    install_argocd
    install_vault
    install_gitlab
    
    log "=== Platform Deployment Completed ==="
    log "Access URLs:"
    log "- GitLab: https://gitlab.$DOMAIN"
    log "- ArgoCD: https://argocd.$DOMAIN"
    log "- Grafana: https://grafana.$DOMAIN"
    log "- Kibana: https://kibana.$DOMAIN"
}

main "$@"
```

---

## üìñ –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –∏ —à–ø–∞—Ä–≥–∞–ª–∫–∏

### Docker
```bash
# –û—á–∏—Å—Ç–∫–∞
docker system prune -a
docker volume prune

# –õ–æ–≥–∏
docker logs -f <container>
docker logs --tail 100 <container>

# Exec
docker exec -it <container> bash
docker exec <container> cat /etc/hosts

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
docker stats
docker top <container>
```

### Kubernetes
```bash
# Pods
kubectl get pods -A
kubectl describe pod <pod-name>
kubectl logs -f <pod-name>
kubectl exec -it <pod-name> -- bash

# Deployments
kubectl rollout status deployment/<name>
kubectl rollout history deployment/<name>
kubectl rollout undo deployment/<name>

# Debug
kubectl get events --sort-by='.lastTimestamp'
kubectl top nodes
kubectl top pods
```

### Git
```bash
# –ü–æ–ª–µ–∑–Ω—ã–µ –∞–ª–∏–∞—Å—ã
git config --global alias.lg "log --graph --pretty=format:'%Cred%h%Creset -%C(yellow)%d%Creset %s %Cgreen(%cr) %C(bold blue)<%an>%Creset' --abbrev-commit"
git config --global alias.st status
git config --global alias.co checkout
git config --global alias.br branch
```

---

## üéì –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–∑—É—á–µ–Ω–∏—é

### Junior —É—Ä–æ–≤–µ–Ω—å
- –û—Å–Ω–æ–≤—ã Linux
- Bash scripting
- Git basics
- Docker basics
- CI/CD –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏

### Middle —É—Ä–æ–≤–µ–Ω—å
- Kubernetes
- Terraform
- Ansible
- Monitoring & Logging
- Cloud providers

### Senior —É—Ä–æ–≤–µ–Ω—å
- Service Mesh
- Security & Compliance
- Cost Optimization
- Disaster Recovery
- Team Leadership

---

## ‚úÖ –ß–µ–∫–ª–∏—Å—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏

### Junior DevOps Engineer
- [ ] –ú–æ–≥—É –Ω–∞–ø–∏—Å–∞—Ç—å bash —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏
- [ ] –ü–æ–Ω–∏–º–∞—é –æ—Å–Ω–æ–≤—ã Docker
- [ ] –ù–∞—Å—Ç—Ä–æ–∏–ª –±–∞–∑–æ–≤—ã–π CI/CD pipeline
- [ ] –£–º–µ—é —Ä–∞–±–æ—Ç–∞—Ç—å —Å Git
- [ ] –ù–∞—Å—Ç—Ä–æ–∏–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–µ—Ä–≤–∏—Å–∞

### Middle DevOps