# –°–±–æ—Ä–Ω–∏–∫ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á DevOps
## –î–ª—è –æ—Ç—Ä–∞–±–æ—Ç–∫–∏ –Ω–∞ Proxmox/Linux (Fedora/Ubuntu)

---

## üü¢ JUNIOR DEVOPS ENGINEER

### –ó–∞–¥–∞—á–∞ 1: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –±—ç–∫–∞–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö PostgreSQL
**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –ë–î —Å —Ä–æ—Ç–∞—Ü–∏–µ–π

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –°–æ–∑–¥–∞—Ç—å –¥–∞–º–ø PostgreSQL –±–∞–∑—ã
- –ò—Å–∫–ª—é—á–∏—Ç—å —Ç–∞–±–ª–∏—Ü—É `logs` –∏–∑ –±—ç–∫–∞–ø–∞
- –î–æ–±–∞–≤–∏—Ç—å timestamp –∫ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
- –°–∂–∞—Ç—å –≤ .tar.gz
- –•—Ä–∞–Ω–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –±—ç–∫–∞–ø–æ–≤
- –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —á–µ—Ä–µ–∑ cron –Ω–∞ –∑–∞–ø—É—Å–∫ –≤ 2:00

**–†–µ—à–µ–Ω–∏–µ:**

```bash
#!/bin/bash
# backup_postgres.sh

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
DB_NAME="myapp"
DB_USER="postgres"
BACKUP_DIR="/var/backups/postgresql"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="backup_${DB_NAME}_${TIMESTAMP}.sql"
RETENTION_DAYS=7

# –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
mkdir -p $BACKUP_DIR

# –°–æ–∑–¥–∞—ë–º –¥–∞–º–ø –∏—Å–∫–ª—é—á–∞—è —Ç–∞–±–ª–∏—Ü—É logs
pg_dump -U $DB_USER \
  --exclude-table=logs \
  --format=plain \
  $DB_NAME > $BACKUP_DIR/$BACKUP_FILE

# –°–∂–∏–º–∞–µ–º
tar -czf $BACKUP_DIR/$BACKUP_FILE.tar.gz -C $BACKUP_DIR $BACKUP_FILE
rm $BACKUP_DIR/$BACKUP_FILE

# –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –±—ç–∫–∞–ø—ã
find $BACKUP_DIR -name "backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
if [ $? -eq 0 ]; then
    echo "[$(date)] Backup successful: $BACKUP_FILE.tar.gz" >> /var/log/db_backup.log
else
    echo "[$(date)] Backup FAILED" >> /var/log/db_backup.log
    exit 1
fi
```

**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ PostgreSQL –Ω–∞ Ubuntu/Fedora:**
```bash
# Ubuntu
sudo apt update && sudo apt install postgresql postgresql-contrib -y

# Fedora
sudo dnf install postgresql postgresql-server -y
sudo postgresql-setup --initdb
sudo systemctl enable --now postgresql

# –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–π –±–∞–∑—ã
sudo -u postgres psql -c "CREATE DATABASE myapp;"
sudo -u postgres psql -d myapp -c "CREATE TABLE logs (id serial, message text);"
sudo -u postgres psql -d myapp -c "CREATE TABLE users (id serial, name text);"
```

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞ cron:**
```bash
# –î–æ–±–∞–≤–∏—Ç—å –ø—Ä–∞–≤–∞ –Ω–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
chmod +x /path/to/backup_postgres.sh

# –î–æ–±–∞–≤–∏—Ç—å –≤ crontab
crontab -e
# –î–æ–±–∞–≤–∏—Ç—å —Å—Ç—Ä–æ–∫—É:
0 2 * * * /path/to/backup_postgres.sh
```

---

### –ó–∞–¥–∞—á–∞ 2: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ CPU –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–µ—Ä–≤–∏—Å–∞
**–¶–µ–ª—å:** –ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU –ø—Ä–æ—Ü–µ—Å—Å–æ–º –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞—Ç—å –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–∞

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –ü—Ä–æ–≤–µ—Ä—è—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
- –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç >80% CPU –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –º–∏–Ω—É—Ç
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–∏—Å
- –û—Ç–ø—Ä–∞–≤–∏—Ç—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –≤ –ª–æ–≥

**–†–µ—à–µ–Ω–∏–µ:**

```bash
#!/bin/bash
# monitor_cpu.sh

SERVICE_NAME="nginx"  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ –≤–∞—à —Å–µ—Ä–≤–∏—Å
CPU_THRESHOLD=80
CHECK_COUNT=5
COUNTER_FILE="/tmp/cpu_high_counter_${SERVICE_NAME}"
LOG_FILE="/var/log/cpu_monitor.log"

# –ü–æ–ª—É—á–∞–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ CPU –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–∞
CPU_USAGE=$(ps aux | grep -v grep | grep $SERVICE_NAME | awk '{sum+=$3} END {print int(sum)}')

# –ï—Å–ª–∏ –ø—Ä–æ—Ü–µ—Å—Å –Ω–µ –Ω–∞–π–¥–µ–Ω
if [ -z "$CPU_USAGE" ]; then
    echo "[$(date)] Service $SERVICE_NAME not running" >> $LOG_FILE
    exit 1
fi

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞
if [ $CPU_USAGE -gt $CPU_THRESHOLD ]; then
    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫
    if [ -f $COUNTER_FILE ]; then
        COUNT=$(cat $COUNTER_FILE)
        COUNT=$((COUNT + 1))
    else
        COUNT=1
    fi
    echo $COUNT > $COUNTER_FILE
    
    echo "[$(date)] High CPU: ${CPU_USAGE}% (count: ${COUNT}/${CHECK_COUNT})" >> $LOG_FILE
    
    # –ï—Å–ª–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–µ 5 —Ä–∞–∑ –ø–æ–¥—Ä—è–¥ - –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º
    if [ $COUNT -ge $CHECK_COUNT ]; then
        echo "[$(date)] RESTARTING $SERVICE_NAME due to high CPU" >> $LOG_FILE
        systemctl restart $SERVICE_NAME
        rm -f $COUNTER_FILE
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        # echo "Service $SERVICE_NAME restarted due to high CPU" | mail -s "Alert" admin@example.com
    fi
else
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á—ë—Ç—á–∏–∫ –µ—Å–ª–∏ CPU –≤ –Ω–æ—Ä–º–µ
    rm -f $COUNTER_FILE
fi
```

**–ù–∞—Å—Ç—Ä–æ–π–∫–∞:**
```bash
chmod +x /path/to/monitor_cpu.sh

# –î–æ–±–∞–≤–∏—Ç—å –≤ crontab –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
* * * * * /path/to/monitor_cpu.sh
```

---

### –ó–∞–¥–∞—á–∞ 3: CI/CD Pipeline –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
**–¶–µ–ª—å:** –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥–µ–ø–ª–æ–π –ø—Ä–∏ push –≤ Git

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Git hooks –∏–ª–∏ Gitea/Gitlab –Ω–∞ Proxmox
- –ü—Ä–∏ push –≤ master –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ø–ª–æ–∏—Ç—å
- –ó–∞–ø—É—Å–∫–∞—Ç—å —Ç–µ—Å—Ç—ã –ø–µ—Ä–µ–¥ –¥–µ–ø–ª–æ–µ–º
- –û—Ç–∫–∞—Ç—ã–≤–∞—Ç—å—Å—è –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â—É—é –≤–µ—Ä—Å–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ

**–†–µ—à–µ–Ω–∏–µ (—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Git hooks):**

**1. –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:**
```bash
# –°–æ–∑–¥–∞—ë–º –ø—Ä–æ—Å—Ç–æ–µ Node.js –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
mkdir ~/myapp && cd ~/myapp
npm init -y
npm install express

# app.js
cat > app.js << 'EOF'
const express = require('express');
const app = express();
const PORT = 3000;

app.get('/', (req, res) => {
    res.send('Hello DevOps!');
});

app.get('/health', (req, res) => {
    res.status(200).json({ status: 'OK' });
});

app.listen(PORT, () => {
    console.log(`Server running on port ${PORT}`);
});
EOF

# test.js
cat > test.js << 'EOF'
const http = require('http');

http.get('http://localhost:3000/health', (res) => {
    if (res.statusCode === 200) {
        console.log('Tests PASSED');
        process.exit(0);
    } else {
        console.log('Tests FAILED');
        process.exit(1);
    }
}).on('error', (e) => {
    console.error('Tests FAILED:', e.message);
    process.exit(1);
});
EOF
```

**2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Git —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:**
```bash
# –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ —Å–æ–∑–¥–∞—ë–º bare —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
sudo mkdir -p /opt/git/myapp.git
cd /opt/git/myapp.git
sudo git init --bare
```

**3. Post-receive hook –¥–ª—è –∞–≤—Ç–æ–¥–µ–ø–ª–æ—è:**
```bash
# /opt/git/myapp.git/hooks/post-receive
cat > /opt/git/myapp.git/hooks/post-receive << 'EOF'
#!/bin/bash

DEPLOY_DIR="/var/www/myapp"
BACKUP_DIR="/var/www/myapp_backup"
LOG_FILE="/var/log/deploy.log"

echo "[$(date)] Starting deployment..." >> $LOG_FILE

# –°–æ–∑–¥–∞—ë–º backup —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
if [ -d $DEPLOY_DIR ]; then
    rm -rf $BACKUP_DIR
    cp -r $DEPLOY_DIR $BACKUP_DIR
    echo "[$(date)] Backup created" >> $LOG_FILE
fi

# –ö–ª–æ–Ω–∏—Ä—É–µ–º –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
rm -rf $DEPLOY_DIR
git clone /opt/git/myapp.git $DEPLOY_DIR

cd $DEPLOY_DIR

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
npm install >> $LOG_FILE 2>&1

# –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
pm2 stop myapp 2>/dev/null || true
pm2 start app.js --name myapp

# –ñ–¥—ë–º –∑–∞–ø—É—Å–∫–∞
sleep 3

# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
node test.js >> $LOG_FILE 2>&1

if [ $? -eq 0 ]; then
    echo "[$(date)] Deployment SUCCESSFUL" >> $LOG_FILE
    rm -rf $BACKUP_DIR
else
    echo "[$(date)] Tests FAILED. Rolling back..." >> $LOG_FILE
    pm2 stop myapp
    rm -rf $DEPLOY_DIR
    mv $BACKUP_DIR $DEPLOY_DIR
    cd $DEPLOY_DIR
    pm2 start app.js --name myapp
    echo "[$(date)] Rollback completed" >> $LOG_FILE
    exit 1
fi
EOF

chmod +x /opt/git/myapp.git/hooks/post-receive
```

**4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# –ù–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ
cd ~/myapp
git init
git add .
git commit -m "Initial commit"
git remote add origin ssh://user@your-server:/opt/git/myapp.git
git push origin master  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –¥–µ–ø–ª–æ–π
```

---

### –ó–∞–¥–∞—á–∞ 4: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Nginx reverse proxy —Å SSL
**–¶–µ–ª—å:** –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Nginx –∫–∞–∫ –æ–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –¥–ª—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è —Å HTTPS

**–†–µ—à–µ–Ω–∏–µ:**

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Nginx
# Ubuntu
sudo apt install nginx certbot python3-certbot-nginx -y

# Fedora
sudo dnf install nginx certbot python3-certbot-nginx -y

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Nginx
sudo cat > /etc/nginx/sites-available/myapp << 'EOF'
upstream backend {
    server 127.0.0.1:3000;
}

server {
    listen 80;
    server_name myapp.local;

    location / {
        proxy_pass http://backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Websocket support
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
    
    # Health check
    location /nginx-health {
        access_log off;
        return 200 "healthy\n";
    }
}
EOF

# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –∫–æ–Ω—Ñ–∏–≥
sudo ln -s /etc/nginx/sites-available/myapp /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl restart nginx

# –î–ª—è —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω–æ–≥–æ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞ (—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ)
sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 \
    -keyout /etc/ssl/private/nginx-selfsigned.key \
    -out /etc/ssl/certs/nginx-selfsigned.crt \
    -subj "/C=US/ST=State/L=City/O=Org/CN=myapp.local"
```

---

## üü° MIDDLE DEVOPS ENGINEER

### –ó–∞–¥–∞—á–∞ 5: –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫–∞–∫ –∫–æ–¥ - Terraform –¥–ª—è Proxmox
**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–æ–∑–¥–∞–Ω–∏–µ VM –≤ Proxmox —á–µ—Ä–µ–∑ Terraform

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:**
- –°–æ–∑–¥–∞—Ç—å –º–æ–¥—É–ª—å Terraform –¥–ª—è VM
- –ü–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞—Ç—å CPU, RAM, –¥–∏—Å–∫
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å cloud-init –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è—Ç—å SSH –∫–ª—é—á–∏

**–†–µ—à–µ–Ω–∏–µ:**

**1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Terraform:**
```bash
# Fedora/Ubuntu
wget https://releases.hashicorp.com/terraform/1.6.0/terraform_1.6.0_linux_amd64.zip
unzip terraform_1.6.0_linux_amd64.zip
sudo mv terraform /usr/local/bin/
```

**2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Proxmox API:**
```bash
# –ù–∞ Proxmox —Å–µ—Ä–≤–µ—Ä–µ —Å–æ–∑–¥–∞—Ç—å API —Ç–æ–∫–µ–Ω
pveum user add terraform@pve
pveum aclmod / -user terraform@pve -role Administrator
pveum user token add terraform@pve terraform-token --privsep=0
```

**3. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ Terraform –ø—Ä–æ–µ–∫—Ç–∞:**
```hcl
# main.tf
terraform {
  required_providers {
    proxmox = {
      source  = "telmate/proxmox"
      version = "2.9.14"
    }
  }
}

provider "proxmox" {
  pm_api_url      = var.proxmox_api_url
  pm_api_token_id = var.proxmox_api_token_id
  pm_api_token_secret = var.proxmox_api_token_secret
  pm_tls_insecure = true
}

# VM Module
resource "proxmox_vm_qemu" "devops_vm" {
  count       = var.vm_count
  name        = "${var.vm_name}-${count.index + 1}"
  target_node = var.proxmox_node
  clone       = var.template_name
  
  cores   = var.cpu_cores
  sockets = 1
  memory  = var.memory
  
  disk {
    size    = var.disk_size
    type    = "scsi"
    storage = var.storage
  }
  
  network {
    model  = "virtio"
    bridge = "vmbr0"
  }
  
  # Cloud-init
  ipconfig0 = "ip=${var.ip_address_base}.${count.index + 10}/24,gw=${var.gateway}"
  
  sshkeys = file(var.ssh_public_key_file)
  
  lifecycle {
    ignore_changes = [
      network,
    ]
  }
}

# variables.tf
variable "proxmox_api_url" {
  description = "Proxmox API URL"
  type        = string
}

variable "proxmox_api_token_id" {
  description = "Proxmox API Token ID"
  type        = string
  sensitive   = true
}

variable "proxmox_api_token_secret" {
  description = "Proxmox API Token Secret"
  type        = string
  sensitive   = true
}

variable "proxmox_node" {
  description = "Proxmox node name"
  type        = string
  default     = "pve"
}

variable "vm_name" {
  description = "Base name for VMs"
  type        = string
  default     = "devops-vm"
}

variable "vm_count" {
  description = "Number of VMs to create"
  type        = number
  default     = 1
}

variable "cpu_cores" {
  description = "Number of CPU cores"
  type        = number
  default     = 2
}

variable "memory" {
  description = "RAM in MB"
  type        = number
  default     = 2048
}

variable "disk_size" {
  description = "Disk size"
  type        = string
  default     = "20G"
}

variable "storage" {
  description = "Storage location"
  type        = string
  default     = "local-lvm"
}

variable "template_name" {
  description = "Template name to clone"
  type        = string
  default     = "ubuntu-22-04-template"
}

variable "ip_address_base" {
  description = "Base IP address"
  type        = string
  default     = "192.168.1"
}

variable "gateway" {
  description = "Gateway IP"
  type        = string
  default     = "192.168.1.1"
}

variable "ssh_public_key_file" {
  description = "Path to SSH public key"
  type        = string
  default     = "~/.ssh/id_rsa.pub"
}

# outputs.tf
output "vm_ips" {
  value = proxmox_vm_qemu.devops_vm[*].default_ipv4_address
}

output "vm_names" {
  value = proxmox_vm_qemu.devops_vm[*].name
}
```

**4. –§–∞–π–ª –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö terraform.tfvars:**
```hcl
proxmox_api_url          = "https://192.168.1.100:8006/api2/json"
proxmox_api_token_id     = "terraform@pve!terraform-token"
proxmox_api_token_secret = "your-secret-token"
vm_count                 = 3
cpu_cores                = 2
memory                   = 4096
```

**5. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
terraform init
terraform plan
terraform apply

# –£–Ω–∏—á—Ç–æ–∂–µ–Ω–∏–µ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
terraform destroy
```

---

### –ó–∞–¥–∞—á–∞ 6: Kubernetes –∫–ª–∞—Å—Ç–µ—Ä –Ω–∞ Proxmox VM (K3s)
**–¶–µ–ª—å:** –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã–π Kubernetes –∫–ª–∞—Å—Ç–µ—Ä

**–†–µ—à–µ–Ω–∏–µ:**

```bash
#!/bin/bash
# install_k3s_cluster.sh

# –ù–∞ –º–∞—Å—Ç–µ—Ä-–Ω–æ–¥–µ
curl -sfL https://get.k3s.io | sh -s - server \
  --write-kubeconfig-mode 644 \
  --disable traefik

# –ü–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –¥–ª—è worker –Ω–æ–¥
sudo cat /var/lib/rancher/k3s/server/node-token

# –ù–∞ worker –Ω–æ–¥–∞—Ö
K3S_URL=https://master-ip:6443
K3S_TOKEN=your-node-token

curl -sfL https://get.k3s.io | K3S_URL=$K3S_URL K3S_TOKEN=$K3S_TOKEN sh -

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞ (–Ω–∞ –º–∞—Å—Ç–µ—Ä–µ)
kubectl get nodes
kubectl get pods -A
```

**–î–µ–ø–ª–æ–π —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è:**
```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-demo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:alpine
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
  - port: 80
    targetPort: 80
```

```bash
kubectl apply -f deployment.yaml
kubectl get svc
```

---

### –ó–∞–¥–∞—á–∞ 7: –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ (Prometheus + Grafana)
**–¶–µ–ª—å:** –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å—Ç–µ–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –¥–ª—è –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

**–†–µ—à–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Docker Compose:**

```yaml
# docker-compose.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    volumes:
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3000:3000"
    restart: unless-stopped
    depends_on:
      - prometheus

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
    ports:
      - "9093:9093"
    restart: unless-stopped

volumes:
  prometheus_data:
  grafana_data:
```

**prometheus.yml:**
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['alertmanager:9093']

rule_files:
  - "alerts.yml"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
      
  - job_name: 'nginx'
    static_configs:
      - targets: ['192.168.1.10:9113']  # nginx-exporter
```

**alerts.yml:**
```yaml
groups:
  - name: system_alerts
    interval: 30s
    rules:
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for 5 minutes"

      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 85%"

      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}) * 100 < 15
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Disk space is low"
          description: "Less than 15% disk space available"
```

**–ó–∞–ø—É—Å–∫:**
```bash
docker-compose up -d

# –î–æ—Å—Ç—É–ø:
# Grafana: http://localhost:3000 (admin/admin)
# Prometheus: http://localhost:9090
```

---

## üî¥ SENIOR DEVOPS ENGINEER

### –ó–∞–¥–∞—á–∞ 8: GitOps —Å ArgoCD –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
**–¶–µ–ª—å:** –í–Ω–µ–¥—Ä–∏—Ç—å GitOps –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è Kubernetes

**–†–µ—à–µ–Ω–∏–µ:**

**1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ ArgoCD:**
```bash
kubectl create namespace argocd
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

# –ü–æ–ª—É—á–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω—ã–π –ø–∞—Ä–æ–ª—å
kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d

# Port-forward –¥–ª—è –¥–æ—Å—Ç—É–ø–∞
kubectl port-forward svc/argocd-server -n argocd 8080:443
```

**2. –°—Ç—Ä—É–∫—Ç—É—Ä–∞ GitOps —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è:**
```
gitops-repo/
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ dev/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ myapp/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ service.yaml
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ kustomization.yaml
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ myapp/
‚îÇ   ‚îî‚îÄ‚îÄ production/
‚îÇ       ‚îî‚îÄ‚îÄ myapp/
‚îî‚îÄ‚îÄ argocd/
    ‚îú‚îÄ‚îÄ applications/
    ‚îÇ   ‚îú‚îÄ‚îÄ myapp-dev.yaml
    ‚îÇ   ‚îú‚îÄ‚îÄ myapp-staging.yaml
    ‚îÇ   ‚îî‚îÄ‚îÄ myapp-prod.yaml
    ‚îî‚îÄ‚îÄ projects/
        ‚îî‚îÄ‚îÄ myapp-project.yaml
```

**3. ArgoCD Application –º–∞–Ω–∏—Ñ–µ—Å—Ç:**
```yaml
# argocd/applications/myapp-dev.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: myapp-dev
  namespace: argocd
spec:
  project: default
  
  source:
    repoURL: https://github.com/yourorg/gitops-repo.git
    targetRevision: main
    path: apps/dev/myapp
  
  destination:
    server: https://kubernetes.default.svc
    namespace: dev
  
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: false
    syncOptions:
    - CreateNamespace=true
    
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m
```

**4. CI/CD Pipeline —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º:**
```yaml
# .github/workflows/deploy.yml
name: Build and Deploy

on:
  push:
    branches: [ main ]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Build Docker image
        run: |
          docker build -t myapp:${{ github.sha }} .
          docker tag myapp:${{ github.sha }} myapp:latest
      
      - name: Push to registry
        run: |
          echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin
          docker push myapp:${{ github.sha }}
          docker push myapp:latest
      
      - name: Update GitOps repo
        run: |
          git clone https://${{ secrets.GIT_TOKEN }}@github.com/yourorg/gitops-repo.git
          cd gitops-repo
          
          # –û–±–Ω–æ–≤–∏—Ç—å image tag –≤ Kubernetes –º–∞–Ω–∏—Ñ–µ—Å—Ç–µ
          sed -i "s|image: myapp:.*|image: myapp:${{ github.sha }}|g" apps/dev/myapp/deployment.yaml
          
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add .
          git commit -m "Update myapp to ${{ github.sha }}"
          git push
```

---

### –ó–∞–¥–∞—á–∞ 9: High Availability PostgreSQL –∫–ª–∞—Å—Ç–µ—Ä —Å Patroni
**–¶–µ–ª—å:** –†–∞–∑–≤–µ—Ä–Ω—É—Ç—å –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤—ã–π –∫–ª–∞—Å—Ç–µ—Ä –ë–î

**–†–µ—à–µ–Ω–∏–µ:**

```bash
#!/bin/bash
# –°–∫—Ä–∏–ø—Ç —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞ –∫–∞–∂–¥—É—é –Ω–æ–¥—É (3 –Ω–æ–¥—ã –º–∏–Ω–∏–º—É–º)

# 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
sudo apt update
sudo apt install -y postgresql postgresql-contrib etcd python3-pip python3-psycopg2

# 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Patroni
sudo pip3 install patroni[etcd]

# 3. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Patroni
sudo cat > /etc/patroni.yml << EOF
scope: postgres-cluster
namespace: /db/
name: $(hostname)

restapi:
  listen: 0.0.0.0:8008
  connect_address: $(hostname -I | awk '{print $1}'):8008

etcd:
  hosts: 192.168.1.10:2379,192.168.1.11:2379,192.168.1.12:2379

bootstrap:
  dcs:
    ttl: 30
    loop_wait: 10
    retry_timeout: 10
    maximum_lag_on_failover: 1048576
    postgresql:
      use_pg_rewind: true
      parameters:
        max_connections: 100
        shared_buffers: 256MB

  initdb:
    - encoding: UTF8
    - data-checksums

  pg_hba:
    - host replication replicator 0.0.0.0/0 md5
    - host all all 0.0.0.0/0 md5

postgresql:
  listen: 0.0.0.0:5432
  connect_address: $(hostname -I | awk '{print $1}'):5432
  data_dir: /var/lib/postgresql/14/main
  bin_dir: /usr/lib/postgresql/14/bin
  authentication:
    replication:
      username: replicator
      password: rep-pass
    superuser:
      username: postgres
      password: postgres-pass

tags:
    nofailover: false
    noloadbalance: false
    clonefrom: false
    nosync: false
EOF

# 4. Systemd service
sudo cat > /etc/systemd/system/patroni.service << EOF
[Unit]
Description=Patroni (PostgreSQL HA)
After=syslog.target network.target

[Service]
Type=simple
User=postgres
Group=postgres
ExecStart=/usr/local/bin/patroni /etc/patroni.yml
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
TimeoutSec=30
Restart=no

[Install]
WantedBy=multi-user.target
EOF

sudo systemctl daemon-reload
sudo systemctl enable patroni
sudo systemctl start patroni
```

**HAProxy –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:**
```bash
# /etc/haproxy/haproxy.cfg
global
    maxconn 100

defaults
    log global
    mode tcp
    retries 2
    timeout client 30m
    timeout connect 4s
    timeout server 30m
    timeout check 5s

listen postgres
    bind *:5000
    option httpchk
    http-check expect status 200
    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions
    server pg1 192.168.1.10:5432 maxconn 100 check port 8008
    server pg2 192.168.1.11:5432 maxconn 100 check port 8008
    server pg3 192.168.1.12:5432 maxconn 100 check port 8008
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∞:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å –∫–ª–∞—Å—Ç–µ—Ä–∞
patronictl -c /etc/patroni.yml list

# –†—É—á–Ω–æ–π failover (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
patronictl -c /etc/patroni.yml failover

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –º–∞—Å—Ç–µ—Ä—É
psql -h 127.0.0.1 -p 5000 -U postgres

# –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —Ä–µ–ø–ª–∏–∫–∞–º (read-only)
psql -h 127.0.0.1 -p 5001 -U postgres
```

---

### –ó–∞–¥–∞—á–∞ 10: –ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª Disaster Recovery —Å –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–µ–π
**–¶–µ–ª—å:** –°–æ–∑–¥–∞—Ç—å —Å–∏—Å—Ç–µ–º—É —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –≤—Å–µ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã

**–†–µ—à–µ–Ω–∏–µ:**

**1. –°–∫—Ä–∏–ø—Ç –ø–æ–ª–Ω–æ–≥–æ –±—ç–∫–∞–ø–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã:**
```bash
#!/bin/bash
# disaster_recovery_backup.sh

set -euo pipefail

BACKUP_ROOT="/mnt/backup"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="$BACKUP_ROOT/$TIMESTAMP"
LOG_FILE="/var/log/dr_backup.log"
RETENTION_DAYS=30

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

error_exit() {
    log "ERROR: $1"
    exit 1
}

# –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
mkdir -p $BACKUP_DIR/{databases,configs,containers,vms,apps}

log "=== Starting Disaster Recovery Backup ==="

# 1. Backup –≤—Å–µ—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
log "Backing up databases..."
backup_databases() {
    # PostgreSQL
    if systemctl is-active --quiet postgresql; then
        pg_dumpall -U postgres | gzip > $BACKUP_DIR/databases/postgresql_all.sql.gz
        log "PostgreSQL backup completed"
    fi
    
    # MySQL/MariaDB
    if systemctl is-active --quiet mysql; then
        mysqldump --all-databases --single-transaction | gzip > $BACKUP_DIR/databases/mysql_all.sql.gz
        log "MySQL backup completed"
    fi
    
    # MongoDB
    if systemctl is-active --quiet mongod; then
        mongodump --out=$BACKUP_DIR/databases/mongodb
        tar -czf $BACKUP_DIR/databases/mongodb.tar.gz -C $BACKUP_DIR/databases mongodb
        rm -rf $BACKUP_DIR/databases/mongodb
        log "MongoDB backup completed"
    fi
}

# 2. Backup –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
log "Backing up system configurations..."
backup_configs() {
    tar -czf $BACKUP_DIR/configs/etc.tar.gz \
        /etc/nginx \
        /etc/apache2 \
        /etc/haproxy \
        /etc/systemd/system \
        /etc/ssh \
        /etc/hosts \
        /etc/fstab \
        2>/dev/null || true
    
    # Docker configs
    if command -v docker &> /dev/null; then
        cp -r /etc/docker $BACKUP_DIR/configs/ 2>/dev/null || true
    fi
    
    # Kubernetes configs
    if [ -d ~/.kube ]; then
        cp -r ~/.kube $BACKUP_DIR/configs/
    fi
    
    log "Configuration backup completed"
}

# 3. Backup Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –∏ volumes
log "Backing up Docker containers..."
backup_docker() {
    if command -v docker &> /dev/null; then
        # –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        docker ps -a --format "{{.Names}}" > $BACKUP_DIR/containers/container_list.txt
        
        # Backup docker-compose —Ñ–∞–π–ª–æ–≤
        find /opt /home -name "docker-compose.yml" -exec cp --parents {} $BACKUP_DIR/containers/ \; 2>/dev/null || true
        
        # Backup volumes
        docker volume ls -q | while read volume; do
            docker run --rm -v $volume:/data -v $BACKUP_DIR/containers:/backup \
                alpine tar czf /backup/volume_$volume.tar.gz -C /data .
        done
        
        log "Docker backup completed"
    fi
}

# 4. Backup Proxmox VMs (–µ—Å–ª–∏ –∑–∞–ø—É—â–µ–Ω–æ –Ω–∞ Proxmox —Ö–æ—Å—Ç–µ)
log "Backing up VM configurations..."
backup_vms() {
    if command -v pvesh &> /dev/null; then
        pvesh get /cluster/resources --type vm --output-format json > $BACKUP_DIR/vms/vm_list.json
        cp -r /etc/pve $BACKUP_DIR/vms/ 2>/dev/null || true
        log "VM configuration backup completed"
    fi
}

# 5. Backup –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
log "Backing up applications..."
backup_apps() {
    # Web –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    if [ -d /var/www ]; then
        tar -czf $BACKUP_DIR/apps/var_www.tar.gz /var/www 2>/dev/null || true
    fi
    
    # –î–æ–º–∞—à–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    if [ -d /opt ]; then
        tar -czf $BACKUP_DIR/apps/opt.tar.gz /opt 2>/dev/null || true
    fi
    
    log "Application backup completed"
}

# 6. –°–æ–∑–¥–∞–Ω–∏–µ –º–∞–Ω–∏—Ñ–µ—Å—Ç–∞ –±—ç–∫–∞–ø–∞
create_manifest() {
    cat > $BACKUP_DIR/manifest.json << EOF
{
    "timestamp": "$TIMESTAMP",
    "hostname": "$(hostname)",
    "os": "$(lsb_release -d | cut -f2)",
    "kernel": "$(uname -r)",
    "backup_size": "$(du -sh $BACKUP_DIR | cut -f1)",
    "databases": $(ls -1 $BACKUP_DIR/databases 2>/dev/null | wc -l),
    "containers": $(cat $BACKUP_DIR/containers/container_list.txt 2>/dev/null | wc -l),
    "completion_time": "$(date '+%Y-%m-%d %H:%M:%S')"
}
EOF
    log "Manifest created"
}

# 7. –°–æ–∑–¥–∞–Ω–∏–µ recovery –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π
create_recovery_guide() {
    cat > $BACKUP_DIR/RECOVERY_GUIDE.md << 'EOF'
# Disaster Recovery Guide

## –ë—ã—Å—Ç—Ä–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ

### 1. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
```bash
# PostgreSQL
gunzip -c databases/postgresql_all.sql.gz | psql -U postgres

# MySQL
gunzip -c databases/mysql_all.sql.gz | mysql -u root -p

# MongoDB
tar -xzf databases/mongodb.tar.gz
mongorestore mongodb/
```

### 2. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
```bash
cd configs
tar -xzf etc.tar.gz -C /
systemctl daemon-reload
```

### 3. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ Docker
```bash
# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å volumes
cd containers
for vol in volume_*.tar.gz; do
    name=$(echo $vol | sed 's/volume_//;s/.tar.gz//')
    docker volume create $name
    docker run --rm -v $name:/data -v $(pwd):/backup alpine \
        tar xzf /backup/$vol -C /data
done

# –ó–∞–ø—É—Å—Ç–∏—Ç—å docker-compose –ø—Ä–æ–µ–∫—Ç—ã
find . -name "docker-compose.yml" -execdir docker-compose up -d \;
```

### 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–µ—Ä–≤–∏—Å—ã
systemctl status postgresql mysql nginx docker

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Docker
docker ps
docker volume ls

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
psql -U postgres -c "SELECT version();"
```

## –ö–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è —ç–∫—Å—Ç—Ä–µ–Ω–Ω–æ–π –ø–æ–º–æ—â–∏
- DevOps Team: devops@company.com
- On-call: +1-555-0100
EOF
    log "Recovery guide created"
}

# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –±—ç–∫–∞–ø–æ–≤
backup_databases
backup_configs
backup_docker
backup_vms
backup_apps
create_manifest
create_recovery_guide

# –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–≥–æ –∞—Ä—Ö–∏–≤–∞
log "Creating final archive..."
cd $BACKUP_ROOT
tar -czf backup_$TIMESTAMP.tar.gz $TIMESTAMP

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
log "Cleaning old backups..."
find $BACKUP_ROOT -name "backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete
find $BACKUP_ROOT -maxdepth 1 -type d -mtime +$RETENTION_DAYS -exec rm -rf {} \;

# –†–∞—Å—á–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã
sha256sum backup_$TIMESTAMP.tar.gz > backup_$TIMESTAMP.tar.gz.sha256

log "=== Backup completed successfully ==="
log "Backup location: $BACKUP_ROOT/backup_$TIMESTAMP.tar.gz"
log "Backup size: $(du -h $BACKUP_ROOT/backup_$TIMESTAMP.tar.gz | cut -f1)"

# –û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
if command -v curl &> /dev/null; then
    curl -X POST https://hooks.slack.com/services/YOUR/WEBHOOK/URL \
        -H 'Content-Type: application/json' \
        -d "{\"text\":\"‚úÖ DR Backup completed: $TIMESTAMP\"}" 2>/dev/null || true
fi
```

**2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ:**
```bash
#!/bin/bash
# disaster_recovery_restore.sh

set -euo pipefail

if [ $# -lt 1 ]; then
    echo "Usage: $0 <backup_file.tar.gz> [--full|--databases|--configs]"
    exit 1
fi

BACKUP_FILE=$1
MODE=${2:-"--full"}
TEMP_DIR="/tmp/dr_restore_$"
LOG_FILE="/var/log/dr_restore.log"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a $LOG_FILE
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã
verify_backup() {
    if [ -f "$BACKUP_FILE.sha256" ]; then
        log "Verifying backup integrity..."
        sha256sum -c "$BACKUP_FILE.sha256" || {
            log "ERROR: Backup integrity check failed!"
            exit 1
        }
        log "Backup integrity verified"
    fi
}

# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±—ç–∫–∞–ø–∞
extract_backup() {
    log "Extracting backup..."
    mkdir -p $TEMP_DIR
    tar -xzf $BACKUP_FILE -C $TEMP_DIR --strip-components=1
    log "Backup extracted to $TEMP_DIR"
}

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö
restore_databases() {
    log "Restoring databases..."
    
    if [ -f "$TEMP_DIR/databases/postgresql_all.sql.gz" ]; then
        log "Restoring PostgreSQL..."
        systemctl stop postgresql || true
        gunzip -c $TEMP_DIR/databases/postgresql_all.sql.gz | sudo -u postgres psql
        systemctl start postgresql
        log "PostgreSQL restored"
    fi
    
    if [ -f "$TEMP_DIR/databases/mysql_all.sql.gz" ]; then
        log "Restoring MySQL..."
        systemctl stop mysql || true
        gunzip -c $TEMP_DIR/databases/mysql_all.sql.gz | mysql -u root
        systemctl start mysql
        log "MySQL restored"
    fi
}

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
restore_configs() {
    log "Restoring configurations..."
    
    if [ -f "$TEMP_DIR/configs/etc.tar.gz" ]; then
        tar -xzf $TEMP_DIR/configs/etc.tar.gz -C /
        systemctl daemon-reload
        log "System configurations restored"
    fi
}

# –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ Docker
restore_docker() {
    log "Restoring Docker environment..."
    
    # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ volumes
    for vol_backup in $TEMP_DIR/containers/volume_*.tar.gz; do
        if [ -f "$vol_backup" ]; then
            vol_name=$(basename $vol_backup | sed 's/volume_//;s/.tar.gz//')
            log "Restoring volume: $vol_name"
            docker volume create $vol_name 2>/dev/null || true
            docker run --rm -v $vol_name:/data -v $TEMP_DIR/containers:/backup \
                alpine tar xzf /backup/$(basename $vol_backup) -C /data
        fi
    done
    
    log "Docker volumes restored"
}

# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
main() {
    log "=== Starting Disaster Recovery Restore ==="
    log "Backup file: $BACKUP_FILE"
    log "Mode: $MODE"
    
    verify_backup
    extract_backup
    
    case $MODE in
        --full)
            restore_databases
            restore_configs
            restore_docker
            ;;
        --databases)
            restore_databases
            ;;
        --configs)
            restore_configs
            ;;
        *)
            log "Unknown mode: $MODE"
            exit 1
            ;;
    esac
    
    # –û—á–∏—Å—Ç–∫–∞
    rm -rf $TEMP_DIR
    
    log "=== Restore completed successfully ==="
    log "Please verify all services are running correctly"
    log "Run: systemctl status postgresql mysql nginx docker"
}

# –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –ø–µ—Ä–µ–¥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
read -p "This will restore from backup. Continue? (yes/no) " -n 3 -r
echo
if [[ $REPLY =~ ^yes$ ]]; then
    main
else
    echo "Restore cancelled"
    exit 0
fi
```

**3. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –±—ç–∫–∞–ø–∞:**
```bash
# –î–æ–±–∞–≤–∏—Ç—å –≤ crontab
sudo crontab -e

# –ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –±—ç–∫–∞–ø –≤ 3:00
0 3 * * * /usr/local/bin/disaster_recovery_backup.sh

# –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è (–≤ —Ç–µ—Å—Ç–æ–≤–æ–π —Å—Ä–µ–¥–µ)
0 4 * * 0 /usr/local/bin/test_dr_restore.sh
```

---

### –ó–∞–¥–∞—á–∞ 11: –ú–Ω–æ–≥–æ—Ä–µ–≥–∏–æ–Ω–∞–ª—å–Ω—ã–π Terraform —Å remote state
**–¶–µ–ª—å:** –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–µ–≥–∏–æ–Ω–∞—Ö/–¥–∞—Ç–∞-—Ü–µ–Ω—Ç—Ä–∞—Ö

**–†–µ—à–µ–Ω–∏–µ:**

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞:**
```
terraform-multi-region/
‚îú‚îÄ‚îÄ global/
‚îÇ   ‚îú‚îÄ‚îÄ backend.tf
‚îÇ   ‚îî‚îÄ‚îÄ versions.tf
‚îú‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ network/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outputs.tf
‚îÇ   ‚îú‚îÄ‚îÄ compute/
‚îÇ   ‚îî‚îÄ‚îÄ database/
‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îú‚îÄ‚îÄ production/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ region-eu/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ backend.tf
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ region-us/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ main.tf
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ backend.tf
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ terraform.tfvars
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îî‚îÄ‚îÄ development/
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ deploy-all.sh
    ‚îî‚îÄ‚îÄ validate-all.sh
```

**1. Backend –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (S3 –∏–ª–∏ MinIO –Ω–∞ Proxmox):**
```hcl
# global/backend.tf
terraform {
  backend "s3" {
    bucket         = "terraform-state"
    key            = "global/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}
```

**2. –ú–æ–¥—É–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è VM:**
```hcl
# modules/compute/main.tf
variable "vm_name" {
  type = string
}

variable "cpu_cores" {
  type    = number
  default = 2
}

variable "memory" {
  type    = number
  default = 2048
}

variable "disk_size" {
  type    = string
  default = "20G"
}

variable "network_config" {
  type = object({
    ip      = string
    gateway = string
    netmask = string
  })
}

variable "tags" {
  type    = map(string)
  default = {}
}

resource "proxmox_vm_qemu" "vm" {
  name        = var.vm_name
  target_node = var.target_node
  clone       = var.template_name
  
  cores   = var.cpu_cores
  sockets = 1
  memory  = var.memory
  
  disk {
    size    = var.disk_size
    type    = "scsi"
    storage = var.storage
  }
  
  network {
    model  = "virtio"
    bridge = "vmbr0"
  }
  
  ipconfig0 = "ip=${var.network_config.ip}/${var.network_config.netmask},gw=${var.network_config.gateway}"
  
  tags = join(",", [for k, v in var.tags : "${k}=${v}"])
  
  lifecycle {
    create_before_destroy = true
  }
}

output "vm_id" {
  value = proxmox_vm_qemu.vm.id
}

output "vm_ip" {
  value = var.network_config.ip
}
```

**3. Environment-specific –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
```hcl
# environments/production/region-eu/main.tf
terraform {
  backend "s3" {
    bucket = "terraform-state"
    key    = "production/eu/terraform.tfstate"
    region = "us-east-1"
  }
}

locals {
  region      = "eu"
  environment = "production"
  
  common_tags = {
    Environment = local.environment
    Region      = local.region
    ManagedBy   = "Terraform"
    Team        = "DevOps"
  }
}

module "web_servers" {
  source = "../../../modules/compute"
  count  = var.web_server_count
  
  vm_name    = "web-${local.region}-${count.index + 1}"
  cpu_cores  = 4
  memory     = 8192
  disk_size  = "50G"
  
  network_config = {
    ip      = "10.0.1.${count.index + 10}"
    gateway = "10.0.1.1"
    netmask = "24"
  }
  
  tags = merge(local.common_tags, {
    Role = "WebServer"
    Name = "web-${local.region}-${count.index + 1}"
  })
}

module "database_servers" {
  source = "../../../modules/compute"
  count  = var.db_server_count
  
  vm_name    = "db-${local.region}-${count.index + 1}"
  cpu_cores  = 8
  memory     = 16384
  disk_size  = "200G"
  
  network_config = {
    ip      = "10.0.2.${count.index + 10}"
    gateway = "10.0.2.1"
    netmask = "24"
  }
  
  tags = merge(local.common_tags, {
    Role = "Database"
    Name = "db-${local.region}-${count.index + 1}"
  })
}

output "web_server_ips" {
  value = module.web_servers[*].vm_ip
}

output "database_server_ips" {
  value = module.database_servers[*].vm_ip
}
```

**4. –°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ–ø–ª–æ—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤:**
```bash
#!/bin/bash
# scripts/deploy-all.sh

set -euo pipefail

ENVIRONMENTS=("production" "staging")
REGIONS=("region-eu" "region-us")

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

deploy_region() {
    local env=$1
    local region=$2
    local path="environments/$env/$region"
    
    log "Deploying $env/$region..."
    
    cd $path
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    terraform init -upgrade
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è
    terraform validate
    
    # –ü–ª–∞–Ω
    terraform plan -out=tfplan
    
    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ (—Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º)
    if [ "${AUTO_APPROVE:-false}" = "true" ]; then
        terraform apply tfplan
    else
        terraform apply tfplan
    fi
    
    # –û—á–∏—Å—Ç–∫–∞
    rm -f tfplan
    
    cd - > /dev/null
    
    log "‚úì Completed $env/$region"
}

# –î–µ–ø–ª–æ–π production —Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º
for region in "${REGIONS[@]}"; do
    deploy_region "production" "$region"
done

# –î–µ–ø–ª–æ–π staging –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
AUTO_APPROVE=true
for region in "${REGIONS[@]}"; do
    deploy_region "staging" "$region"
done

log "All deployments completed successfully"
```

---

### –ó–∞–¥–∞—á–∞ 12: –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å Ansible - Configuration Management
**–¶–µ–ª—å:** –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–µ—Ä–≤–µ—Ä–æ–≤

**–†–µ—à–µ–Ω–∏–µ:**

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ Ansible –ø—Ä–æ–µ–∫—Ç–∞:**
```
ansible/
‚îú‚îÄ‚îÄ ansible.cfg
‚îú‚îÄ‚îÄ inventory/
‚îÇ   ‚îú‚îÄ‚îÄ production/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hosts.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ group_vars/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ all.yml
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ webservers.yml
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ databases.yml
‚îÇ   ‚îî‚îÄ‚îÄ staging/
‚îú‚îÄ‚îÄ roles/
‚îÇ   ‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ files/
‚îÇ   ‚îú‚îÄ‚îÄ webserver/
‚îÇ   ‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îú‚îÄ‚îÄ playbooks/
‚îÇ   ‚îú‚îÄ‚îÄ site.yml
‚îÇ   ‚îú‚îÄ‚îÄ webservers.yml
‚îÇ   ‚îî‚îÄ‚îÄ databases.yml
‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ deploy.sh
```

**1. Inventory —Ñ–∞–π–ª:**
```yaml
# inventory/production/hosts.yml
all:
  children:
    webservers:
      hosts:
        web1:
          ansible_host: 192.168.1.10
          ansible_user: deploy
        web2:
          ansible_host: 192.168.1.11
          ansible_user: deploy
        web3:
          ansible_host: 192.168.1.12
          ansible_user: deploy
    
    databases:
      hosts:
        db1:
          ansible_host: 192.168.1.20
          ansible_user: deploy
          postgres_role: master
        db2:
          ansible_host: 192.168.1.21
          ansible_user: deploy
          postgres_role: replica
    
    loadbalancers:
      hosts:
        lb1:
          ansible_host: 192.168.1.30
          ansible_user: deploy
    
    monitoring:
      hosts:
        monitor1:
          ansible_host: 192.168.1.40
          ansible_user: deploy
```

**2. Group variables:**
```yaml
# inventory/production/group_vars/all.yml
---
ansible_python_interpreter: /usr/bin/python3
ansible_ssh_private_key_file: ~/.ssh/id_rsa

# Common packages
common_packages:
  - vim
  - htop
  - curl
  - wget
  - git
  - net-tools

# NTP Configuration
ntp_servers:
  - 0.pool.ntp.org
  - 1.pool.ntp.org

# Monitoring
node_exporter_version: "1.6.1"
prometheus_server: "192.168.1.40:9090"

# Backup
backup_destination: "/mnt/backup"
backup_retention_days: 30
```

```yaml
# inventory/production/group_vars/webservers.yml
---
nginx_version: latest
nginx_worker_processes: auto
nginx_worker_connections: 1024

app_name: "myapp"
app_port: 3000
app_user: "appuser"
app_directory: "/opt/{{ app_name }}"

ssl_certificate: "/etc/ssl/certs/{{ app_name }}.crt"
ssl_certificate_key: "/etc/ssl/private/{{ app_name }}.key"
```

**3. Common role:**
```yaml
# roles/common/tasks/main.yml
---
- name: Update package cache
  apt:
    update_cache: yes
    cache_valid_time: 3600
  when: ansible_os_family == "Debian"

- name: Install common packages
  package:
    name: "{{ common_packages }}"
    state: present

- name: Configure timezone
  timezone:
    name: UTC

- name: Configure NTP
  template:
    src: ntp.conf.j2
    dest: /etc/ntp.conf
  notify: restart ntp

- name: Create deploy user
  user:
    name: deploy
    groups: sudo
    shell: /bin/bash
    create_home: yes

- name: Add SSH key for deploy user
  authorized_key:
    user: deploy
    key: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"

- name: Configure sudo without password
  lineinfile:
    path: /etc/sudoers.d/deploy
    line: 'deploy ALL=(ALL) NOPASSWD: ALL'
    create: yes
    validate: 'visudo -cf %s'

- name: Install node_exporter
  include_tasks: node_exporter.yml

- name: Configure firewall
  include_tasks: firewall.yml
```

**4. Webserver role:**
```yaml
# roles/webserver/tasks/main.yml
---
- name: Install Nginx
  apt:
    name: nginx
    state: present

- name: Create application user
  user:
    name: "{{ app_user }}"
    system: yes
    create_home: no

- name: Create application directory
  file:
    path: "{{ app_directory }}"
    state: directory
    owner: "{{ app_user }}"
    group: "{{ app_user }}"
    mode: '0755'

- name: Deploy application configuration
  template:
    src: nginx-app.conf.j2
    dest: "/etc/nginx/sites-available/{{ app_name }}"
  notify: reload nginx

- name: Enable application site
  file:
    src: "/etc/nginx/sites-available/{{ app_name }}"
    dest: "/etc/nginx/sites-enabled/{{ app_name }}"
    state: link
  notify: reload nginx

- name: Remove default site
  file:
    path: /etc/nginx/sites-enabled/default
    state: absent
  notify: reload nginx

- name: Ensure Nginx is running
  systemd:
    name: nginx
    state: started
    enabled: yes

- name: Configure log rotation
  template:
    src: logrotate.conf.j2
    dest: "/etc/logrotate.d/{{ app_name }}"
```

**5. Template –¥–ª—è Nginx:**
```jinja2
# roles/webserver/templates/nginx-app.conf.j2
upstream {{ app_name }}_backend {
    least_conn;
    {% for host in groups['webservers'] %}
    server {{ hostvars[host].ansible_host }}:{{ app_port }} max_fails=3 fail_timeout=30s;
    {% endfor %}
}

server {
    listen 80;
    server_name {{ app_domain | default('_') }};
    
    # Redirect to HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name {{ app_domain | default('_') }};
    
    ssl_certificate {{ ssl_certificate }};
    ssl_certificate_key {{ ssl_certificate_key }};
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;
    
    access_log /var/log/nginx/{{ app_name }}_access.log;
    error_log /var/log/nginx/{{ app_name }}_error.log;
    
    location / {
        proxy_pass http://{{ app_name }}_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        proxy_connect_timeout 60s;
        proxy_send_timeout 60s;
        proxy_read_timeout 60s;
    }
    
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
```

**6. Main playbook:**
```yaml
# playbooks/site.yml
---
- name: Configure all servers
  hosts: all
  become: yes
  roles:
    - common

- name: Configure web servers
  hosts: webservers
  become: yes
  roles:
    - webserver
  tags: webservers

- name: Configure database servers
  hosts: databases
  become: yes
  roles:
    - database
  tags: databases

- name: Configure load balancers
  hosts: loadbalancers
  become: yes
  roles:
    - loadbalancer
  tags: loadbalancers

- name: Configure monitoring
  hosts: monitoring
  become: yes
  roles:
    - prometheus
    - grafana
  tags: monitoring
```

**7. Deployment script:**
```bash
#!/bin/bash
# scripts/deploy.sh

set -euo pipefail

INVENTORY=${1:-"production"}
TAGS=${2:-"all"}
CHECK_MODE=${CHECK_MODE:-false}

echo "Deploying to: $INVENTORY"
echo "Tags: $TAGS"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞
ansible-playbook playbooks/site.yml \
    -i inventory/$INVENTORY/hosts.yml \
    --syntax-check

# Dry-run
if [ "$CHECK_MODE" = "true" ]; then
    ansible-playbook playbooks/site.yml \
        -i inventory/$INVENTORY/hosts.yml \
        --tags "$TAGS" \
        --check \
        --diff
    exit 0
fi

# –†–µ–∞–ª—å–Ω—ã–π –¥–µ–ø–ª–æ–π
ansible-playbook playbooks/site.yml \
    -i inventory/$INVENTORY/hosts.yml \
    --tags "$TAGS" \
    -v

echo "Deployment completed!"
```

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
CHECK_MODE=true ./scripts/deploy.sh production

# –î–µ–ø–ª–æ–π —Ç–æ–ª—å–∫–æ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–æ–≤
./scripts/deploy.sh production webservers

# –î–µ–ø–ª–æ–π –≤—Å–µ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
./scripts/deploy.sh production all

# Ad-hoc –∫–æ–º–∞–Ω–¥—ã
ansible all -i inventory/production/hosts.yml -m ping
ansible webservers -i inventory/production/hosts.yml -a "systemctl status nginx"
```

---

### –ó–∞–¥–∞—á–∞ 13: Security Hardening –∏ Compliance
**–¶–µ–ª—å:** –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º

**–†–µ—à–µ–Ω–∏–µ:**

**1. –°–∫—Ä–∏–ø—Ç –∞—É–¥–∏—Ç–∞ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏:**
```bash
#!/bin/bash
# security_audit.sh

set -euo pipefail

REPORT_DIR="/var/log/security_audit"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
REPORT_FILE="$REPORT_DIR/audit_$TIMESTAMP.html"

mkdir -p $REPORT_DIR

# HTML Header
cat > $REPORT_FILE << 'EOF'
<!DOCTYPE html>
<html>
<head>
    <title>Security Audit Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .pass { color: green; font-weight: bold; }
        .fail { color: red; font-weight: bold; }
        .warn { color: orange; font-weight: bold; }
        table { border-collapse: collapse; width: 100%; margin: 20px 0; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #4CAF50; color: white; }
        .section { margin-top: 30px; }
    </style>
</head>
<body>
EOF

echo "<h1>Security Audit Report</h1>" >> $REPORT_FILE
echo "<p>Generated: $(date)</p>" >> $REPORT_FILE
echo "<p>Hostname: $(hostname)</p>" >> $REPORT_FILE
echo "<p>OS: $(lsb_release -d | cut -f2)</p>" >> $REPORT_FILE

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
add_check() {
    local title=$1
    local status=$2
    local details=$3
    
    echo "<div class='section'>" >> $REPORT_FILE
    echo "<h3>$title</h3>" >> $REPORT_FILE
    echo "<p class='$status'>Status: $status</p>" >> $REPORT_FILE
    echo "<pre>$details</pre>" >> $REPORT_FILE
    echo "</div>" >> $REPORT_FILE
}

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π —Å–∏—Å—Ç–µ–º—ã
echo "Checking system updates..."
if apt list --upgradable 2>/dev/null | grep -q upgradable; then
    UPDATES=$(apt list --upgradable 2>/dev/null | grep upgradable | wc -l)
    add_check "System Updates" "warn" "$UPDATES security updates available"
else
    add_check "System Updates" "pass" "System is up to date"
fi

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ø–æ—Ä—Ç–æ–≤
echo "Checking open ports..."
OPEN_PORTS=$(ss -tuln | grep LISTEN)
add_check "Open Ports" "warn" "$OPEN_PORTS"

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ SSH –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
echo "Checking SSH configuration..."
SSH_ISSUES=""

if grep -q "^PermitRootLogin yes" /etc/ssh/sshd_config 2>/dev/null; then
    SSH_ISSUES+="‚ùå Root login is enabled\n"
fi

if grep -q "^PasswordAuthentication yes" /etc/ssh/sshd_config 2>/dev/null; then
    SSH_ISSUES+="‚ùå Password authentication is enabled\n"
fi

if [ -z "$SSH_ISSUES" ]; then
    add_check "SSH Configuration" "pass" "SSH is properly configured"
else
    add_check "SSH Configuration" "fail" "$SSH_ISSUES"
fi

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ firewall
echo "Checking firewall..."
if systemctl is-active --quiet ufw || systemctl is-active --quiet firewalld; then
    FIREWALL_STATUS=$(ufw status 2>/dev/null || firewall-cmd --state 2>/dev/null)
    add_check "Firewall" "pass" "Firewall is active: $FIREWALL_STATUS"
else
    add_check "Firewall" "fail" "No firewall is active"
fi

# 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ fail2ban
echo "Checking fail2ban..."
if systemctl is-active --quiet fail2ban; then
    FAIL2BAN_STATUS=$(fail2ban-client status 2>/dev/null || echo "Running")
    add_check "Fail2ban" "pass" "Fail2ban is active: $FAIL2BAN_STATUS"
else
    add_check "Fail2ban" "warn" "Fail2ban is not installed or not running"
fi

# 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –Ω–∞ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Ñ–∞–π–ª—ã
echo "Checking file permissions..."
PERM_ISSUES=""

if [ $(stat -c %a /etc/passwd) != "644" ]; then
    PERM_ISSUES+="‚ùå /etc/passwd has incorrect permissions\n"
fi

if [ $(stat -c %a /etc/shadow) != "640" ] && [ $(stat -c %a /etc/shadow) != "600" ]; then
    PERM_ISSUES+="‚ùå /etc/shadow has incorrect permissions\n"
fi

if [ -z "$PERM_ISSUES" ]; then
    add_check "File Permissions" "pass" "Critical files have correct permissions"
else
    add_check "File Permissions" "fail" "$PERM_ISSUES"
fi

# 7. –ü—Ä–æ–≤–µ—Ä–∫–∞ SUID/SGID —Ñ–∞–π–ª–æ–≤
echo "Checking SUID/SGID files..."
SUID_FILES=$(find / -type f \( -perm -4000 -o -perm -2000 \) 2>/dev/null | head -20)
add_check "SUID/SGID Files" "warn" "Found SUID/SGID files (showing first 20):\n$SUID_FILES"

# 8. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—É–¥–∞—á–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –≤—Ö–æ–¥–∞
echo "Checking failed login attempts..."
FAILED_LOGINS=$(grep "Failed password" /var/log/auth.log 2>/dev/null | tail -10 || echo "No recent failed attempts")
add_check "Failed Login Attempts" "warn" "$FAILED_LOGINS"

# 9. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
echo "Checking running services..."
SERVICES=$(systemctl list-units --type=service --state=running | grep running)
add_check "Running Services" "pass" "$SERVICES"

# 10. –ü—Ä–æ–≤–µ—Ä–∫–∞ Docker –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
if command -v docker &> /dev/null; then
    echo "Checking Docker security..."
    
    DOCKER_ISSUES=""
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ privileged –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
    PRIV_CONTAINERS=$(docker ps --filter "status=running" --format "{{.ID}}" | xargs -I {} docker inspect {} --format '{{.Name}}: Privileged={{.HostConfig.Privileged}}' | grep "Privileged=true" || echo "")
    
    if [ -n "$PRIV_CONTAINERS" ]; then
        DOCKER_ISSUES+="‚ùå Privileged containers found:\n$PRIV_CONTAINERS\n"
    fi
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Å root
    ROOT_CONTAINERS=$(docker ps --format "{{.Names}}" | xargs -I {} docker exec {} whoami 2>/dev/null | grep -c "root" || echo "0")
    
    if [ "$ROOT_CONTAINERS" != "0" ]; then
        DOCKER_ISSUES+="‚ö†Ô∏è  $ROOT_CONTAINERS containers running as root\n"
    fi
    
    if [ -z "$DOCKER_ISSUES" ]; then
        add_check "Docker Security" "pass" "Docker containers are properly configured"
    else
        add_check "Docker Security" "fail" "$DOCKER_ISSUES"
    fi
fi

# 11. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ /etc
echo "Checking recent /etc changes..."
RECENT_CHANGES=$(find /etc -type f -mtime -7 2>/dev/null | head -20)
add_check "Recent /etc Changes" "warn" "Files modified in last 7 days:\n$RECENT_CHANGES"

# 12. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–∫–æ–≤–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
echo "Checking disk space..."
DISK_USAGE=$(df -h | awk '$5+0 > 80 {print $0}')
if [ -n "$DISK_USAGE" ]; then
    add_check "Disk Space" "fail" "Partitions with >80% usage:\n$DISK_USAGE"
else
    add_check "Disk Space" "pass" "All partitions have sufficient space"
fi

# HTML Footer
cat >> $REPORT_FILE << 'EOF'
<div class='section'>
    <h3>Recommendations</h3>
    <ul>
        <li>Disable root SSH login</li>
        <li>Use SSH keys instead of passwords</li>
        <li>Keep system updated</li>
        <li>Enable and configure firewall</li>
        <li>Install fail2ban for brute-force protection</li>
        <li>Regular security audits</li>
        <li>Monitor logs for suspicious activity</li>
    </ul>
</div>
</body>
</html>
EOF

echo "Audit report generated: $REPORT_FILE"

# –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç—á–µ—Ç–∞ –ø–æ email (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
if command -v mail &> /dev/null; then
    cat $REPORT_FILE | mail -s "Security Audit Report - $(hostname)" -a "Content-Type: text/html" security@company.com
fi

# –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Slack (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
if [ -n "${SLACK_WEBHOOK:-}" ]; then
    curl -X POST $SLACK_WEBHOOK \
        -H 'Content-Type: application/json' \
        -d "{\"text\":\"üîí Security audit completed for $(hostname). Report: $REPORT_FILE\"}"
fi
```

**2. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π:**
```bash
#!/bin/bash
# security_hardening.sh

set -euo pipefail

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

log "Starting security hardening..."

# 1. SSH Hardening
log "Hardening SSH..."
cat > /etc/ssh/sshd_config.d/99-hardening.conf << 'EOF'
# Disable root login
PermitRootLogin no

# Disable password authentication
PasswordAuthentication no
PubkeyAuthentication yes

# Disable empty passwords
PermitEmptyPasswords no

# Disable X11 forwarding
X11Forwarding no

# Use only strong ciphers
Ciphers chacha20-poly1305@openssh.com,aes256-gcm@openssh.com,aes128-gcm@openssh.com
MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com
KexAlgorithms curve25519-sha256@libssh.org,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512

# Set login grace time
LoginGraceTime 30

# Maximum authentication attempts
MaxAuthTries 3

# Maximum sessions
MaxSessions 2

# Client alive interval
ClientAliveInterval 300
ClientAliveCountMax 2
EOF

systemctl restart sshd
log "SSH hardened"

# 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ firewall
log "Configuring firewall..."
apt install -y ufw

# –†–∞–∑—Ä–µ—à–∏—Ç—å SSH
ufw allow 22/tcp

# –†–∞–∑—Ä–µ—à–∏—Ç—å HTTP/HTTPS
ufw allow 80/tcp
ufw allow 443/tcp

# –í–∫–ª—é—á–∏—Ç—å firewall
ufw --force enable
log "Firewall configured"

# 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ fail2ban
log "Installing fail2ban..."
apt install -y fail2ban

cat > /etc/fail2ban/jail.local << 'EOF'
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 5
destemail = admin@company.com
sendername = Fail2Ban

[sshd]
enabled = true
port = 22
logpath = /var/log/auth.log

[nginx-http-auth]
enabled = true

[nginx-noscript]
enabled = true

[nginx-badbots]
enabled = true
EOF

systemctl enable fail2ban
systemctl restart fail2ban
log "Fail2ban configured"

# 4. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
log "Enabling automatic security updates..."
apt install -y unattended-upgrades

cat > /etc/apt/apt.conf.d/50unattended-upgrades << 'EOF'
Unattended-Upgrade::Allowed-Origins {
    "${distro_id}:${distro_codename}-security";
};
Unattended-Upgrade::AutoFixInterruptedDpkg "true";
Unattended-Upgrade::MinimalSteps "true";
Unattended-Upgrade::Remove-Unused-Kernel-Packages "true";
Unattended-Upgrade::Remove-Unused-Dependencies "true";
Unattended-Upgrade::Automatic-Reboot "false";
Unattended-Upgrade::Mail "admin@company.com";
EOF

systemctl enable unattended-upgrades
log "Automatic updates enabled"

# 5. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∞–π–ª–æ–≤—ã—Ö –ø—Ä–∞–≤
log "Setting correct file permissions..."
chmod 644 /etc/passwd
chmod 640 /etc/shadow
chmod 644 /etc/group
chmod 640 /etc/gshadow
log "File permissions corrected"

# 6. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ auditd
log "Installing auditd..."
apt install -y auditd audispd-plugins

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
auditctl -w /etc/passwd -p wa -k passwd_changes
auditctl -w /etc/shadow -p wa -k shadow_changes
auditctl -w /etc/sudoers -p wa -k sudoers_changes
auditctl -w /var/log/auth.log -p wa -k auth_log_changes

systemctl enable auditd
systemctl start auditd
log "Auditd configured"

# 7. –û—Ç–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
log "Disabling unnecessary services..."
SERVICES_TO_DISABLE=(
    "bluetooth"
    "cups"
    "avahi-daemon"
)

for service in "${SERVICES_TO_DISABLE[@]}"; do
    if systemctl list-unit-files | grep -q "^$service"; then
        systemctl disable $service 2>/dev/null || true
        systemctl stop $service 2>/dev/null || true
    fi
done
log "Unnecessary services disabled"

# 8. Kernel hardening
log "Hardening kernel parameters..."
cat > /etc/sysctl.d/99-security.conf << 'EOF'
# IP Forwarding
net.ipv4.ip_forward = 0
net.ipv6.conf.all.forwarding = 0

# SYN cookies protection
net.ipv4.tcp_syncookies = 1

# Ignore ICMP redirects
net.ipv4.conf.all.accept_redirects = 0
net.ipv6.conf.all.accept_redirects = 0

# Ignore source routed packets
net.ipv4.conf.all.accept_source_route = 0
net.ipv6.conf.all.accept_source_route = 0

# Ignore send redirects
net.ipv4.conf.all.send_redirects = 0

# Disable ICMP redirect acceptance
net.ipv4.conf.default.accept_redirects = 0

# Log Martians
net.ipv4.conf.all.log_martians = 1

# Increase system file descriptor limit
fs.file-max = 65535

# Protect against SYN flood attacks
net.ipv4.tcp_max_syn_backlog = 2048
net.ipv4.tcp_synack_retries = 2
net.ipv4.tcp_syn_retries = 5

# Disable IPv6 if not needed
net.ipv6.conf.all.disable_ipv6 = 1
net.ipv6.conf.default.disable_ipv6 = 1
EOF

sysctl -p /etc/sysctl.d/99-security.conf
log "Kernel parameters hardened"

log "Security hardening completed!"
```

**3. Ansible playbook –¥–ª—è security hardening:**
```yaml
# playbooks/security_hardening.yml
---
- name: Security Hardening
  hosts: all
  become: yes
  
  vars:
    ssh_port: 22
    allowed_users: ["deploy", "admin"]
    fail2ban_bantime: 3600
    
  tasks:
    - name: Update all packages
      apt:
        upgrade: dist
        update_cache: yes
      when: ansible_os_family == "Debian"
    
    - name: Install security packages
      apt:
        name:
          - ufw
          - fail2ban
          - unattended-upgrades
          - auditd
          - aide
          - rkhunter
          - lynis
        state: present
    
    - name: Configure SSH
      template:
        src: templates/sshd_config.j2
        dest: /etc/ssh/sshd_config
        validate: '/usr/sbin/sshd -t -f %s'
      notify: restart sshd
    
    - name: Configure UFW default policies
      ufw:
        direction: "{{ item.direction }}"
        policy: "{{ item.policy }}"
      loop:
        - { direction: 'incoming', policy: 'deny' }
        - { direction: 'outgoing', policy: 'allow' }
    
    - name: Allow SSH through firewall
      ufw:
        rule: allow
        port: "{{ ssh_port }}"
        proto: tcp
    
    - name: Enable UFW
      ufw:
        state: enabled
    
    - name: Configure fail2ban
      template:
        src: templates/jail.local.j2
        dest: /etc/fail2ban/jail.local
      notify: restart fail2ban
    
    - name: Set correct file permissions
      file:
        path: "{{ item.path }}"
        mode: "{{ item.mode }}"
      loop:
        - { path: '/etc/passwd', mode: '0644' }
        - { path: '/etc/shadow', mode: '0640' }
        - { path: '/etc/group', mode: '0644' }
        - { path: '/etc/gshadow', mode: '0640' }
    
    - name: Configure kernel parameters
      sysctl:
        name: "{{ item.name }}"
        value: "{{ item.value }}"
        state: present
        reload: yes
      loop:
        - { name: 'net.ipv4.tcp_syncookies', value: '1' }
        - { name: 'net.ipv4.conf.all.accept_redirects', value: '0' }
        - { name: 'net.ipv4.conf.all.send_redirects', value: '0' }
        - { name: 'net.ipv4.conf.all.log_martians', value: '1' }
    
    - name: Run security audit
      command: lynis audit system --quick
      register: audit_result
      changed_when: false
    
    - name: Save audit report
      copy:
        content: "{{ audit_result.stdout }}"
        dest: "/var/log/security_audit_{{ ansible_date_time.date }}.log"
  
  handlers:
    - name: restart sshd
      service:
        name: sshd
        state: restarted
    
    - name: restart fail2ban
      service:
        name: fail2ban
        state: restarted
```

---

### –ó–∞–¥–∞—á–∞ 14: Blue-Green Deployment —Å –Ω—É–ª–µ–≤—ã–º downtime
**–¶–µ–ª—å:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –¥–µ–ø–ª–æ—è –±–µ–∑ –ø—Ä–æ—Å—Ç–æ—è —Å–µ—Ä–≤–∏—Å–∞

**–†–µ—à–µ–Ω–∏–µ:**

**1. –°–∫—Ä–∏–ø—Ç Blue-Green –¥–µ–ø–ª–æ—è:**
```bash
#!/bin/bash
# blue_green_deploy.sh

set -euo pipefail

APP_NAME="myapp"
BLUE_PORT=3000
GREEN_PORT=3001
HEALTH_CHECK_URL="http://localhost"
NGINX_UPSTREAM="/etc/nginx/conf.d/${APP_NAME}_upstream.conf"
DEPLOY_DIR="/opt/${APP_NAME}"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

error_exit() {
    log "ERROR: $1"
    exit 1
}

# –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–µ–∫—É—â—É—é –∞–∫—Ç–∏–≤–Ω—É—é —Å—Ä–µ–¥—É
get_active_env() {
    if grep -q "server 127.0.0.1:$BLUE_PORT" $NGINX_UPSTREAM && \
       ! grep -q "^[[:space:]]*#.*server 127.0.0.1:$BLUE_PORT" $NGINX_UPSTREAM; then
        echo "blue"
    else
        echo "green"
    fi
}

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
health_check() {
    local port=$1
    local max_attempts=30
    local attempt=0
    
    log "Checking health on port $port..."
    
    while [ $attempt -lt $max_attempts ]; do
        if curl -sf "${HEALTH_CHECK_URL}:${port}/health" > /dev/null; then
            log "Health check passed on port $port"
            return 0
        fi
        
        attempt=$((attempt + 1))
        log "Health check attempt $attempt/$max_attempts failed, retrying..."
        sleep 2
    done
    
    error_exit "Health check failed on port $port after $max_attempts attempts"
}

# –î–µ–ø–ª–æ–π –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
deploy_app() {
    local env=$1
    local port=$2
    
    log "Deploying to $env environment (port $port)..."
    
    # –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é
    pm2 delete ${APP_NAME}-${env} 2>/dev/null || true
    
    # –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–¥ (git pull, docker pull, etc.)
    cd $DEPLOY_DIR
    git pull origin main
    npm install --production
    
    # –ó–∞–ø—É—Å—Ç–∏—Ç—å –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é
    PORT=$port pm2 start app.js --name ${APP_NAME}-${env}
    
    # –ü–æ–¥–æ–∂–¥–∞—Ç—å –∑–∞–ø—É—Å–∫–∞
    sleep 5
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–¥–æ—Ä–æ–≤—å–µ
    health_check $port
}

# –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞—Ñ–∏–∫
switch_traffic() {
    local target_env=$1
    local target_port=$2
    
    log "Switching traffic to $target_env environment..."
    
    # –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π upstream –∫–æ–Ω—Ñ–∏–≥
    cat > $NGINX_UPSTREAM << EOF
upstream ${APP_NAME}_backend {
    server 127.0.0.1:${target_port} max_fails=3 fail_timeout=30s;
}
EOF
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    nginx -t || error_exit "Nginx configuration test failed"
    
    # –ü–ª–∞–≤–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
    nginx -s reload
    
    log "Traffic switched to $target_env"
}

# –û—Ç–∫–∞—Ç
rollback() {
    local current_env=$1
    local previous_env=$2
    local previous_port=$3
    
    log "Rolling back from $current_env to $previous_env..."
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ —Å—Ç–∞—Ä–∞—è –≤–µ—Ä—Å–∏—è –∂–∏–≤–∞
    if ! health_check $previous_port; then
        error_exit "Previous environment is not healthy, manual intervention required"
    fi
    
    # –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –æ–±—Ä–∞—Ç–Ω–æ
    switch_traffic $previous_env $previous_port
    
    log "Rollback completed"
}

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä–æ–π —Å—Ä–µ–¥—ã
cleanup_old_env() {
    local env=$1
    
    log "Cleaning up $env environment..."
    pm2 delete ${APP_NAME}-${env} 2>/dev/null || true
}

# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
main() {
    local active_env=$(get_active_env)
    local target_env
    local target_port
    local previous_port
    
    if [ "$active_env" = "blue" ]; then
        target_env="green"
        target_port=$GREEN_PORT
        previous_port=$BLUE_PORT
    else
        target_env="blue"
        target_port=$BLUE_PORT
        previous_port=$GREEN_PORT
    fi
    
    log "=== Blue-Green Deployment Started ==="
    log "Current active: $active_env"
    log "Deploying to: $target_env"
    
    # 1. –î–µ–ø–ª–æ–π –≤ –Ω–µ–∞–∫—Ç–∏–≤–Ω—É—é —Å—Ä–µ–¥—É
    deploy_app $target_env $target_port
    
    # 2. Smoke tests –Ω–∞ –Ω–æ–≤–æ–π –≤–µ—Ä—Å–∏–∏
    log "Running smoke tests..."
    if ! curl -sf "${HEALTH_CHECK_URL}:${target_port}/health" > /dev/null; then
        error_exit "Smoke tests failed"
    fi
    
    # 3. –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞—Ñ–∏–∫
    switch_traffic $target_env $target_port
    
    # 4. –ü–æ–¥–æ–∂–¥–∞—Ç—å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å
    sleep 10
    
    if ! health_check $target_port; then
        log "New version is unhealthy, rolling back..."
        rollback $target_env $active_env $previous_port
        error_exit "Deployment failed, rolled back"
    fi
    
    # 5. –û—á–∏—Å—Ç–∏—Ç—å —Å—Ç–∞—Ä—É—é —Å—Ä–µ–¥—É
    cleanup_old_env $active_env
    
    log "=== Deployment Completed Successfully ==="
    log "Active environment: $target_env"
    log "Port: $target_port"
}

# –ó–∞–ø—É—Å–∫
main "$@"
```

**2. Kubernetes Blue-Green —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Services:**
```yaml
# blue-green-k8s.yml
---
# Blue Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-blue
  labels:
    app: myapp
    version: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: myapp
        image: myapp:v1.0
        ports:
        - containerPort: 3000
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 3
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"

---
# Green Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-green
  labels:
    app: myapp
    version: green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: myapp
        image: myapp:v2.0
        ports:
        - containerPort: 3000
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 3
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"

---
# Production Service (initially pointing to blue)
apiVersion: v1
kind: Service
metadata:
  name: myapp-production
spec:
  type: LoadBalancer
  selector:
    app: myapp
    version: blue  # Change to 'green' to switch traffic
  ports:
  - port: 80
    targetPort: 3000

---
# Service for Blue environment
apiVersion: v1
kind: Service
metadata:
  name: myapp-blue
spec:
  selector:
    app: myapp
    version: blue
  ports:
  - port: 80
    targetPort: 3000

---
# Service for Green environment
apiVersion: v1
kind: Service
metadata:
  name: myapp-green
spec:
  selector:
    app: myapp
    version: green
  ports:
  - port: 80
    targetPort: 3000
```

**3. –°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏—è –≤ Kubernetes:**
```bash
#!/bin/bash
# k8s_blue_green_switch.sh

set -euo pipefail

APP_NAME="myapp"
NAMESPACE="default"
PRODUCTION_SERVICE="${APP_NAME}-production"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# –ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é –∞–∫—Ç–∏–≤–Ω—É—é –≤–µ—Ä—Å–∏—é
get_active_version() {
    kubectl get service $PRODUCTION_SERVICE -n $NAMESPACE \
        -o jsonpath='{.spec.selector.version}'
}

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å health deployments
check_deployment_health() {
    local version=$1
    local deployment="${APP_NAME}-${version}"
    
    log "Checking health of $deployment..."
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ deployment –≥–æ—Ç–æ–≤
    kubectl rollout status deployment/$deployment -n $NAMESPACE --timeout=5m
    
    # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –≤—Å–µ –ø–æ–¥—ã ready
    local ready_replicas=$(kubectl get deployment $deployment -n $NAMESPACE \
        -o jsonpath='{.status.readyReplicas}')
    local desired_replicas=$(kubectl get deployment $deployment -n $NAMESPACE \
        -o jsonpath='{.spec.replicas}')
    
    if [ "$ready_replicas" != "$desired_replicas" ]; then
        log "ERROR: Only $ready_replicas/$desired_replicas replicas are ready"
        return 1
    fi
    
    log "$deployment is healthy ($ready_replicas/$desired_replicas replicas ready)"
    return 0
}

# –ü–µ—Ä–µ–∫–ª—é—á–∏—Ç—å —Ç—Ä–∞—Ñ–∏–∫
switch_traffic() {
    local target_version=$1
    
    log "Switching traffic to $target_version version..."
    
    kubectl patch service $PRODUCTION_SERVICE -n $NAMESPACE \
        -p "{\"spec\":{\"selector\":{\"version\":\"$target_version\"}}}"
    
    log "Traffic switched to $target_version"
}

# Smoke tests
run_smoke_tests() {
    local service_url=$1
    
    log "Running smoke tests against $service_url..."
    
    # –ü–æ–ª—É—á

listen postgres-replicas
    bind *:5001
    option httpchk GET /replica
    http-check expect status 200
    default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions
    server pg1 192.168.1.10:5432 maxconn 100 check port 8008
    server pg2 192.168.1.11:5432 maxconn 100 check port 8008
    server pg3 192.168.1.12:5432 maxconn 100 check port 8008